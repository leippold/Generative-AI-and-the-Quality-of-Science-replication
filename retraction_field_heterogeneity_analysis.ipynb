{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": "# Retraction Analysis: Field Heterogeneity in AI Detection Difficulty\n\n<a href=\"https://colab.research.google.com/github/leippold/HAI-Frontier/blob/main/retraction_field_heterogeneity_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n\n---\n\n## Motivation\n\nThis notebook addresses a key critique of the Epistemic Trap framework: **Does the AI verification gap vary systematically across scientific fields?**\n\nThe theoretical model predicts that fields with weaker verification infrastructure (lower œÜ) should exhibit:\n1. **Higher baseline retraction rates** (more errors escape detection)\n2. **Larger AI-Human GIGO gaps** (AI contamination harder to detect)\n3. **Faster escalation** of the detection difficulty over time\n\n### Literature Context\n\n**Zhou et al. (2025, arXiv)** document dramatic field differences in retraction rates per 10,000 publications:\n- Physics: 8.1 (strongest verification culture)\n- Chemistry: 16.3\n- Mathematics: 17.2\n- Social Sciences: 38.2\n- Clinical & Life Sciences: 40.3\n- EE & Computer Science: **157.1** (highest rate)\n\n**Replication studies** show similar patterns:\n- Economics: 61% replication rate (Camerer et al., 2016, Science)\n- Psychology: 39% replication rate (Open Science Collaboration, 2015)\n\n### This Notebook\n\nWe extend the GIGO window analysis to examine **field-level heterogeneity**:\n1. **Cross-sectional**: Which fields have the largest AI detection gaps?\n2. **Temporal (High-Frequency)**: Has the gap escalated differently by field?\n3. **Model Validation**: Do empirical patterns match theoretical predictions?\n\n---"
  },
  {
   "cell_type": "markdown",
   "id": "setup-header",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading\n",
    "\n",
    "### 1.1 Environment Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# IMPORTS AND CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "# Standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import mannwhitneyu, kruskal, chi2_contingency\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Statistical modeling\n",
    "try:\n",
    "    from lifelines import KaplanMeierFitter, CoxPHFitter\n",
    "    from lifelines.statistics import logrank_test, multivariate_logrank_test\n",
    "    HAS_LIFELINES = True\n",
    "except ImportError:\n",
    "    HAS_LIFELINES = False\n",
    "    print(\"Warning: lifelines not installed. Run: pip install lifelines\")\n",
    "\n",
    "# Visualization settings\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = [10, 6]\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "plt.rcParams['font.size'] = 11\n",
    "plt.rcParams['axes.titlesize'] = 13\n",
    "plt.rcParams['axes.labelsize'] = 11\n",
    "\n",
    "# Color scheme (consistent with paper figures)\n",
    "COLORS = {\n",
    "    'human': '#2ca02c',      # Green for human papers\n",
    "    'ai': '#d62728',         # Red for AI papers\n",
    "    'neutral': '#2563eb',    # Blue for neutral\n",
    "    'warning': '#ff9800',    # Orange for warnings\n",
    "}\n",
    "\n",
    "# Field colors (for multi-field plots)\n",
    "FIELD_COLORS = plt.cm.Set2(np.linspace(0, 1, 8))\n",
    "\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.width', 200)\n",
    "\n",
    "print(\"Environment configured successfully.\")\n",
    "print(f\"Lifelines available: {HAS_LIFELINES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colab-setup",
   "metadata": {},
   "outputs": [],
   "source": "#@title Configuration { display-mode: \"form\" }\nfrom google.colab import userdata\n\n# Get token from Colab Secrets (set once in sidebar, persists across sessions)\ntry:\n    GITHUB_TOKEN = userdata.get('GITHUB_TOKEN')\n    print(\"‚úì GitHub token loaded from Colab Secrets\")\nexcept:\n    GITHUB_TOKEN = None\n    print(\"‚ö†Ô∏è  No GitHub token found - will skip git push operations\")\n\n#@markdown ### Data Location\n#@markdown Set the path to your data folder (supports Google Drive):\nDATA_PATH = \"/content/drive/MyDrive/HAI_Data\"  #@param {type:\"string\"}\n\n#@markdown Expected files in DATA_PATH:\n#@markdown - `retraction_watch.csv`\n#@markdown - `all_problematic_papers.csv`\n\n#@markdown ---\n#@markdown ### GitHub Configuration (for cloning repo)\nGITHUB_USER = \"leippold\"  #@param {type:\"string\"}\nREPO_NAME = \"HAI-Frontier\"  #@param {type:\"string\"}"
  },
  {
   "cell_type": "code",
   "id": "vh8k2wkjxuj",
   "source": "#@title Mount Google Drive (if using Drive for data)\nimport os\n\n# Only run this if your DATA_PATH is in Google Drive\nif DATA_PATH.startswith(\"/content/drive\"):\n    from google.colab import drive\n    drive.mount('/content/drive')\n    print(\"‚úì Google Drive mounted\")\nelse:\n    print(\"‚ÑπÔ∏è  Skipping Drive mount (DATA_PATH is not in Drive)\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "dwguu9uatzw",
   "source": "#@title Install Dependencies\n!pip install lifelines scipy statsmodels seaborn --quiet\nprint(\"‚úì Dependencies installed\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "yytxg17k8wf",
   "source": "#@title Clone Repository from GitHub\nimport os\n\n# Ensure we're in a valid directory\n%cd /content\n\n# Clean up any existing clone\n!rm -rf /content/{REPO_NAME}\n\n# Clone the repo\nif GITHUB_TOKEN:\n    !git clone https://{GITHUB_TOKEN}@github.com/{GITHUB_USER}/{REPO_NAME}.git\nelse:\n    !git clone https://github.com/{GITHUB_USER}/{REPO_NAME}.git\n\n# Change to repo directory\n%cd /content/{REPO_NAME}\n\n# Repository path for later use\nREPO_PATH = f\"/content/{REPO_NAME}\"\n\nprint(f\"\\n‚úì Repository cloned to: {REPO_PATH}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "data-loading-header",
   "metadata": {},
   "source": [
    "### 1.2 Load Retraction Watch Data\n",
    "\n",
    "We use the standard data loading pipeline from the retraction analysis module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-data",
   "metadata": {},
   "outputs": [],
   "source": "#@title Load Retraction Data\nimport sys\n\n# Setup Python path\nsys.path.insert(0, f\"{REPO_PATH}/retraction_analysis\")\nsys.path.insert(0, f\"{REPO_PATH}/retraction_analysis/retraction_src\")\n\n# Import data loading functions\nfrom data_loading import load_data, define_ai_cohorts, get_cohort_summary\n\n# Data paths from Google Drive\nRETRACTION_PATH = f\"{DATA_PATH}/retraction_watch.csv\"\nPROBLEMATIC_PATH = f\"{DATA_PATH}/all_problematic_papers.csv\"\n\n# Verify data files exist\nprint(f\"üìä Checking data files in: {DATA_PATH}\\n\")\nfor filepath, name in [(RETRACTION_PATH, \"Retraction Watch\"), (PROBLEMATIC_PATH, \"Problematic Papers\")]:\n    if os.path.exists(filepath):\n        size = os.path.getsize(filepath) / 1024 / 1024\n        print(f\"  ‚úì {name}: {size:.1f} MB\")\n    else:\n        print(f\"  ‚ùå {name}: NOT FOUND\")\n\n# Load raw data\nprint(\"\\nLoading data...\")\ntry:\n    rw_df, prob_df = load_data(RETRACTION_PATH, PROBLEMATIC_PATH, start_year=2005)\n    print(f\"‚úì Data loaded successfully!\")\n    print(f\"  Retraction Watch: {len(rw_df):,} records\")\n    print(f\"  Problematic Papers: {len(prob_df):,} records\")\nexcept FileNotFoundError as e:\n    print(f\"‚ùå Data file not found: {e}\")\n    print(\"\\nPlease ensure the data files are in your Google Drive at:\")\n    print(f\"  {DATA_PATH}\")\n    rw_df, prob_df = None, None"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "define-cohorts",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DEFINE AI VS HUMAN COHORTS\n",
    "# =============================================================================\n",
    "\n",
    "if rw_df is not None:\n",
    "    # Define cohorts using detector flags and retraction reasons\n",
    "    df = define_ai_cohorts(\n",
    "        rw_df, \n",
    "        prob_df,\n",
    "        target_detectors=['tortured', 'scigen', 'Seek&Blastn'],\n",
    "        ai_keywords=['generated', 'ChatGPT', 'LLM', 'AI', 'hallucination', \n",
    "                     'fake', 'paper mill', 'tortured phrases', 'fabricat'],\n",
    "        merge_citations=True\n",
    "    )\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"COHORT SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    print(get_cohort_summary(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "field-prep-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Field Classification and Preparation\n",
    "\n",
    "### 2.1 Standardize Subject Areas\n",
    "\n",
    "Retraction Watch uses fine-grained subject classifications. We aggregate these into broader categories aligned with Zhou et al.'s taxonomy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "field-mapping",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# FIELD CLASSIFICATION MAPPING\n",
    "# =============================================================================\n",
    "\n",
    "def map_to_broad_field(subject):\n",
    "    \"\"\"\n",
    "    Map Retraction Watch subject categories to broad fields.\n",
    "    \n",
    "    Aligned with Zhou et al. (2025) taxonomy for comparability.\n",
    "    \n",
    "    Theoretical prediction (from œÜ framework):\n",
    "    - Physics/Math: High œÜ (formal verification) ‚Üí Small AI gap\n",
    "    - Social Sciences: Low œÜ (consensus-based) ‚Üí Large AI gap\n",
    "    - CS/Engineering: Mixed œÜ ‚Üí Variable AI gap\n",
    "    \"\"\"\n",
    "    if not isinstance(subject, str):\n",
    "        return 'Unknown'\n",
    "    \n",
    "    subject_lower = subject.lower()\n",
    "    \n",
    "    # Physics & Astronomy - Strong verification culture\n",
    "    if any(kw in subject_lower for kw in ['physics', 'astronomy', 'astrophysics', \n",
    "                                           'nuclear', 'particle', 'quantum']):\n",
    "        return 'Physics'\n",
    "    \n",
    "    # Mathematics - Formal proof verification\n",
    "    elif any(kw in subject_lower for kw in ['math', 'statistics', 'probability']):\n",
    "        return 'Mathematics'\n",
    "    \n",
    "    # Chemistry - Experimental verification\n",
    "    elif any(kw in subject_lower for kw in ['chemistry', 'chemical', 'biochem']):\n",
    "        return 'Chemistry'\n",
    "    \n",
    "    # Clinical & Life Sciences - High retraction rate (Zhou: 40.3/10k)\n",
    "    elif any(kw in subject_lower for kw in ['medicine', 'medical', 'clinical', 'health',\n",
    "                                             'pharma', 'drug', 'surgery', 'oncology',\n",
    "                                             'cardio', 'neuro', 'psychiatr', 'dental',\n",
    "                                             'nursing', 'public health', 'epidemiol']):\n",
    "        return 'Clinical & Life Sciences'\n",
    "    \n",
    "    # Biology (non-clinical)\n",
    "    elif any(kw in subject_lower for kw in ['biology', 'biological', 'biotech', 'genetic',\n",
    "                                             'molecular', 'cell', 'ecology', 'evolution',\n",
    "                                             'zoology', 'botany', 'microbio']):\n",
    "        return 'Biology'\n",
    "    \n",
    "    # Computer Science & Engineering - Highest retraction rate (Zhou: 157.1/10k)\n",
    "    elif any(kw in subject_lower for kw in ['computer', 'computing', 'software', 'machine learning',\n",
    "                                             'artificial intelligence', 'data science',\n",
    "                                             'engineering', 'electrical', 'mechanical',\n",
    "                                             'civil', 'materials', 'aerospace']):\n",
    "        return 'CS & Engineering'\n",
    "    \n",
    "    # Social Sciences - Consensus-based verification (Zhou: 38.2/10k)\n",
    "    elif any(kw in subject_lower for kw in ['psychology', 'sociology', 'economics', 'political',\n",
    "                                             'anthropology', 'education', 'business', 'management',\n",
    "                                             'finance', 'marketing', 'social', 'behavio']):\n",
    "        return 'Social Sciences'\n",
    "    \n",
    "    # Earth & Environmental\n",
    "    elif any(kw in subject_lower for kw in ['earth', 'environmental', 'climate', 'geology',\n",
    "                                             'ocean', 'atmospheric', 'geography']):\n",
    "        return 'Earth & Environmental'\n",
    "    \n",
    "    # Humanities (typically excluded from STEM analysis)\n",
    "    elif any(kw in subject_lower for kw in ['humanities', 'history', 'philosophy', 'literature',\n",
    "                                             'language', 'art', 'music', 'religion']):\n",
    "        return 'Humanities'\n",
    "    \n",
    "    # Multidisciplinary\n",
    "    elif any(kw in subject_lower for kw in ['multidisciplin', 'interdisciplin', 'general']):\n",
    "        return 'Multidisciplinary'\n",
    "    \n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "\n",
    "# Apply field mapping\n",
    "if df is not None:\n",
    "    # Find the subject column\n",
    "    subject_col = None\n",
    "    for col in ['Subject', 'subject', 'SubjectArea', 'subject_area']:\n",
    "        if col in df.columns:\n",
    "            subject_col = col\n",
    "            break\n",
    "    \n",
    "    if subject_col:\n",
    "        df['broad_field'] = df[subject_col].apply(map_to_broad_field)\n",
    "        print(\"Field mapping applied.\\n\")\n",
    "        print(\"Field distribution:\")\n",
    "        print(df['broad_field'].value_counts())\n",
    "    else:\n",
    "        print(\"Warning: No subject column found in data.\")\n",
    "        print(f\"Available columns: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "field-stats",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# FIELD-LEVEL SUMMARY STATISTICS\n",
    "# =============================================================================\n",
    "\n",
    "if 'broad_field' in df.columns:\n",
    "    print(\"=\"*70)\n",
    "    print(\"FIELD-LEVEL SUMMARY STATISTICS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    field_summary = df.groupby('broad_field').agg({\n",
    "        'is_ai': ['sum', 'count', 'mean'],\n",
    "        'GIGO_Years': ['mean', 'median', 'std']\n",
    "    }).round(3)\n",
    "    \n",
    "    field_summary.columns = ['N_AI', 'N_Total', 'AI_Rate', \n",
    "                             'GIGO_Mean', 'GIGO_Median', 'GIGO_Std']\n",
    "    field_summary['AI_Rate'] = (field_summary['AI_Rate'] * 100).round(1)\n",
    "    field_summary = field_summary.sort_values('N_Total', ascending=False)\n",
    "    \n",
    "    print(\"\\n\" + field_summary.to_string())\n",
    "    \n",
    "    # Theoretical predictions\n",
    "    print(\"\\n\" + \"-\"*70)\n",
    "    print(\"THEORETICAL PREDICTIONS (from œÜ framework)\")\n",
    "    print(\"-\"*70)\n",
    "    print(\"\"\"\n",
    "    Fields with STRONG verification (high œÜ):\n",
    "      - Physics, Mathematics: Expect SMALL AI-Human GIGO gap\n",
    "    \n",
    "    Fields with WEAK verification (low œÜ):\n",
    "      - Social Sciences, CS/Engineering: Expect LARGE AI-Human GIGO gap\n",
    "    \n",
    "    Reference (Zhou et al. 2025 retraction rates per 10k publications):\n",
    "      - Physics: 8.1, Chemistry: 16.3, Math: 17.2\n",
    "      - Social Sciences: 38.2, Clinical/Life: 40.3\n",
    "      - CS/Engineering: 157.1 (highest)\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analysis-1-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Cross-Sectional Analysis: GIGO Window by Field\n",
    "\n",
    "### 3.1 AI vs Human Detection Time by Field\n",
    "\n",
    "For each field, we compare median time to retraction (GIGO Window) between AI and Human papers. The **AI Persistence Premium** = (AI_GIGO - Human_GIGO) / Human_GIGO measures how much longer AI contamination persists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cross-sectional-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CROSS-SECTIONAL ANALYSIS: GIGO WINDOW BY FIELD\n",
    "# =============================================================================\n",
    "\n",
    "def analyze_gigo_by_field(df, min_n_ai=20, min_n_human=50, verbose=True):\n",
    "    \"\"\"\n",
    "    Analyze GIGO window differences between AI and Human papers by field.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "        Must have 'broad_field', 'is_ai', 'GIGO_Years'\n",
    "    min_n_ai : int\n",
    "        Minimum AI papers per field for analysis\n",
    "    min_n_human : int\n",
    "        Minimum Human papers per field\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame with field-level statistics and significance tests\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for field in df['broad_field'].unique():\n",
    "        field_df = df[df['broad_field'] == field]\n",
    "        \n",
    "        ai = field_df[field_df['is_ai'] == 1]['GIGO_Years']\n",
    "        human = field_df[field_df['is_ai'] == 0]['GIGO_Years']\n",
    "        \n",
    "        # Skip if insufficient data\n",
    "        if len(ai) < min_n_ai or len(human) < min_n_human:\n",
    "            continue\n",
    "        \n",
    "        # Statistics\n",
    "        ai_median = ai.median()\n",
    "        human_median = human.median()\n",
    "        persistence_premium = (ai_median - human_median) / human_median * 100\n",
    "        \n",
    "        # Mann-Whitney U test (non-parametric)\n",
    "        u_stat, p_value = mannwhitneyu(ai, human, alternative='two-sided')\n",
    "        \n",
    "        # Effect size (Cliff's delta)\n",
    "        # Range: [-1, 1], magnitude: |d| < 0.147 = negligible, \n",
    "        # 0.147-0.33 = small, 0.33-0.474 = medium, > 0.474 = large\n",
    "        n_ai, n_human = len(ai), len(human)\n",
    "        cliffs_delta = (2 * u_stat / (n_ai * n_human)) - 1\n",
    "        \n",
    "        results.append({\n",
    "            'Field': field,\n",
    "            'N_AI': n_ai,\n",
    "            'N_Human': n_human,\n",
    "            'AI_Median': ai_median,\n",
    "            'Human_Median': human_median,\n",
    "            'Persistence_Premium_%': persistence_premium,\n",
    "            'Cliffs_Delta': cliffs_delta,\n",
    "            'p_value': p_value,\n",
    "            'Significant': 'Yes' if p_value < 0.05 else 'No'\n",
    "        })\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df = results_df.sort_values('Persistence_Premium_%', ascending=False)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"GIGO WINDOW ANALYSIS BY FIELD\")\n",
    "        print(\"Persistence Premium = (AI_GIGO - Human_GIGO) / Human_GIGO √ó 100\")\n",
    "        print(\"=\"*80)\n",
    "        print(\"\\n\" + results_df.round(3).to_string(index=False))\n",
    "        \n",
    "        # Interpretation\n",
    "        print(\"\\n\" + \"-\"*80)\n",
    "        print(\"INTERPRETATION\")\n",
    "        print(\"-\"*80)\n",
    "        \n",
    "        significant_fields = results_df[results_df['Significant'] == 'Yes']\n",
    "        if len(significant_fields) > 0:\n",
    "            top_field = significant_fields.iloc[0]\n",
    "            print(f\"\\n‚Ä¢ Largest AI gap: {top_field['Field']}\")\n",
    "            print(f\"  AI papers persist {top_field['Persistence_Premium_%']:.1f}% longer before detection\")\n",
    "            print(f\"  (AI median: {top_field['AI_Median']:.2f} yrs, Human: {top_field['Human_Median']:.2f} yrs)\")\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "\n",
    "if 'broad_field' in df.columns:\n",
    "    field_results = analyze_gigo_by_field(df, min_n_ai=15, min_n_human=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cross-sectional-viz",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# VISUALIZATION: GIGO WINDOW BY FIELD\n",
    "# =============================================================================\n",
    "\n",
    "if 'field_results' in dir() and field_results is not None:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    # ----- Panel A: Median GIGO by Field (Grouped Bar) -----\n",
    "    ax1 = axes[0]\n",
    "    \n",
    "    # Filter to fields with sufficient data\n",
    "    plot_df = field_results.copy()\n",
    "    fields = plot_df['Field'].tolist()\n",
    "    x = np.arange(len(fields))\n",
    "    width = 0.35\n",
    "    \n",
    "    bars1 = ax1.barh(x - width/2, plot_df['Human_Median'], width, \n",
    "                     label='Human', color=COLORS['human'], alpha=0.8)\n",
    "    bars2 = ax1.barh(x + width/2, plot_df['AI_Median'], width,\n",
    "                     label='AI', color=COLORS['ai'], alpha=0.8)\n",
    "    \n",
    "    ax1.set_yticks(x)\n",
    "    ax1.set_yticklabels(fields)\n",
    "    ax1.set_xlabel('Median Years to Retraction (GIGO Window)')\n",
    "    ax1.set_title('A. Detection Time by Field and Cohort', fontweight='bold')\n",
    "    ax1.legend(loc='lower right')\n",
    "    ax1.invert_yaxis()  # Highest gap at top\n",
    "    ax1.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    # Add significance markers\n",
    "    for i, row in plot_df.iterrows():\n",
    "        if row['Significant'] == 'Yes':\n",
    "            idx = fields.index(row['Field'])\n",
    "            max_val = max(row['AI_Median'], row['Human_Median'])\n",
    "            ax1.text(max_val + 0.3, idx, '*', fontsize=14, ha='center', va='center', color='red')\n",
    "    \n",
    "    # ----- Panel B: Persistence Premium -----\n",
    "    ax2 = axes[1]\n",
    "    \n",
    "    colors = [COLORS['ai'] if p > 0 else COLORS['human'] for p in plot_df['Persistence_Premium_%']]\n",
    "    bars = ax2.barh(fields, plot_df['Persistence_Premium_%'], color=colors, alpha=0.8, edgecolor='black')\n",
    "    \n",
    "    ax2.axvline(x=0, color='black', linestyle='-', linewidth=1)\n",
    "    ax2.axvline(x=47, color='gray', linestyle='--', linewidth=2, \n",
    "                label='Paper aggregate (47%)')\n",
    "    ax2.set_xlabel('AI Persistence Premium (%)')\n",
    "    ax2.set_title('B. How Much Longer AI Papers Persist\\n(Positive = AI harder to detect)', fontweight='bold')\n",
    "    ax2.legend(loc='upper right')\n",
    "    ax2.invert_yaxis()\n",
    "    ax2.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar, val in zip(bars, plot_df['Persistence_Premium_%']):\n",
    "        if val > 0:\n",
    "            ax2.text(val + 2, bar.get_y() + bar.get_height()/2, \n",
    "                    f'+{val:.0f}%', va='center', fontsize=9)\n",
    "        else:\n",
    "            ax2.text(val - 6, bar.get_y() + bar.get_height()/2,\n",
    "                    f'{val:.0f}%', va='center', fontsize=9)\n",
    "    \n",
    "    plt.suptitle('Field Heterogeneity in AI Detection Difficulty', \n",
    "                 fontsize=14, fontweight='bold', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save\n",
    "    plt.savefig('last_results/field_heterogeneity_gigo_comparison.png', \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    print(\"Saved: last_results/field_heterogeneity_gigo_comparison.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analysis-2-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. High-Frequency Escalation Analysis by Field\n",
    "\n",
    "### 4.1 Temporal Evolution of the Detection Gap\n",
    "\n",
    "This replicates the high-frequency GIGO window analysis but **stratified by field**. We track quarterly detection ratios to see if certain fields show faster escalation toward the trap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "high-freq-by-field",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# HIGH-FREQUENCY ESCALATION ANALYSIS BY FIELD\n",
    "# =============================================================================\n",
    "\n",
    "def analyze_escalation_by_field(df, fields_to_analyze=None, start_year=2019, \n",
    "                                 window_quarters=4, min_n=10, verbose=True):\n",
    "    \"\"\"\n",
    "    High-frequency (quarterly) escalation analysis stratified by field.\n",
    "    \n",
    "    Detection Ratio = Median Human GIGO / Median AI GIGO\n",
    "    - Ratio > 1: AI detected faster (humans stay longer)\n",
    "    - Ratio < 1: AI harder to detect (AI stays longer) ‚Üí \"Trap\" territory\n",
    "    - Downward trend = \"Escalating Trap\"\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "    fields_to_analyze : list, optional\n",
    "        Subset of fields (default: top 5 by volume)\n",
    "    start_year : int\n",
    "        Start of analysis window\n",
    "    window_quarters : int\n",
    "        Rolling window size\n",
    "    min_n : int\n",
    "        Minimum papers per period per cohort\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    dict with field-level escalation results\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df['OriginalPaperDate'] = pd.to_datetime(df['OriginalPaperDate'], errors='coerce')\n",
    "    df = df[df['OriginalPaperDate'].dt.year >= start_year]\n",
    "    df['Period'] = df['OriginalPaperDate'].dt.to_period('Q')\n",
    "    \n",
    "    # Default: top fields by volume\n",
    "    if fields_to_analyze is None:\n",
    "        field_counts = df['broad_field'].value_counts()\n",
    "        fields_to_analyze = field_counts.head(6).index.tolist()\n",
    "        # Exclude 'Unknown' and 'Other' if present\n",
    "        fields_to_analyze = [f for f in fields_to_analyze \n",
    "                             if f not in ['Unknown', 'Other', 'Humanities']]\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"HIGH-FREQUENCY ESCALATION ANALYSIS BY FIELD\")\n",
    "        print(\"=\"*70)\n",
    "        print(f\"Fields: {fields_to_analyze}\")\n",
    "        print(f\"Period: {start_year}+, Rolling window: {window_quarters} quarters\")\n",
    "    \n",
    "    all_results = {}\n",
    "    \n",
    "    for field in fields_to_analyze:\n",
    "        field_df = df[df['broad_field'] == field]\n",
    "        periods = sorted(field_df['Period'].unique())\n",
    "        \n",
    "        if len(periods) < window_quarters + 2:\n",
    "            if verbose:\n",
    "                print(f\"\\n{field}: Insufficient temporal coverage\")\n",
    "            continue\n",
    "        \n",
    "        field_results = []\n",
    "        \n",
    "        for i in range(len(periods) - window_quarters + 1):\n",
    "            window_periods = periods[i : i + window_quarters]\n",
    "            window_label = str(window_periods[-1])\n",
    "            \n",
    "            sub_df = field_df[field_df['Period'].isin(window_periods)]\n",
    "            \n",
    "            ai = sub_df[sub_df['is_ai'] == 1]['GIGO_Years']\n",
    "            human = sub_df[sub_df['is_ai'] == 0]['GIGO_Years']\n",
    "            \n",
    "            if len(ai) < min_n or len(human) < min_n:\n",
    "                continue\n",
    "            \n",
    "            ai_med = ai.median()\n",
    "            hu_med = human.median()\n",
    "            \n",
    "            if ai_med > 0 and hu_med > 0:\n",
    "                ratio = hu_med / ai_med\n",
    "                field_results.append({\n",
    "                    'period': window_label,\n",
    "                    'ratio': ratio,\n",
    "                    'n_ai': len(ai),\n",
    "                    'n_human': len(human),\n",
    "                    'ai_median': ai_med,\n",
    "                    'human_median': hu_med\n",
    "                })\n",
    "        \n",
    "        if len(field_results) >= 4:\n",
    "            results_df = pd.DataFrame(field_results)\n",
    "            \n",
    "            # Calculate trend (linear regression slope)\n",
    "            x = np.arange(len(results_df))\n",
    "            y = results_df['ratio'].values\n",
    "            slope, intercept, r_value, p_value, std_err = stats.linregress(x, y)\n",
    "            \n",
    "            all_results[field] = {\n",
    "                'results_df': results_df,\n",
    "                'slope': slope,\n",
    "                'r_squared': r_value**2,\n",
    "                'trend_p': p_value,\n",
    "                'latest_ratio': results_df['ratio'].iloc[-1],\n",
    "                'mean_ratio': results_df['ratio'].mean()\n",
    "            }\n",
    "            \n",
    "            if verbose:\n",
    "                trend_dir = \"DECLINING (trap escalating)\" if slope < 0 else \"STABLE/IMPROVING\"\n",
    "                in_trap = \"YES\" if all_results[field]['latest_ratio'] < 1 else \"No\"\n",
    "                print(f\"\\n{field}:\")\n",
    "                print(f\"  Trend: {slope:.4f}/quarter ({trend_dir})\")\n",
    "                print(f\"  Latest ratio: {all_results[field]['latest_ratio']:.2f}\")\n",
    "                print(f\"  Currently in trap zone (<1): {in_trap}\")\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "\n",
    "# Run analysis\n",
    "if 'broad_field' in df.columns:\n",
    "    escalation_results = analyze_escalation_by_field(\n",
    "        df, \n",
    "        start_year=2018, \n",
    "        window_quarters=4,\n",
    "        min_n=5\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "escalation-viz",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# VISUALIZATION: ESCALATION BY FIELD\n",
    "# =============================================================================\n",
    "\n",
    "if 'escalation_results' in dir() and escalation_results:\n",
    "    n_fields = len(escalation_results)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    # ----- Panel A: Multi-field escalation plot -----\n",
    "    ax1 = axes[0]\n",
    "    \n",
    "    for i, (field, data) in enumerate(escalation_results.items()):\n",
    "        results_df = data['results_df']\n",
    "        color = FIELD_COLORS[i % len(FIELD_COLORS)]\n",
    "        \n",
    "        ax1.plot(range(len(results_df)), results_df['ratio'], \n",
    "                 marker='o', color=color, linewidth=2, alpha=0.8,\n",
    "                 label=f\"{field} (slope={data['slope']:.3f})\")\n",
    "    \n",
    "    ax1.axhline(y=1.0, color='black', linestyle='--', linewidth=2, \n",
    "                label='Equal Detection (Ratio = 1)')\n",
    "    ax1.axhspan(0, 1, alpha=0.1, color='red')  # Danger zone\n",
    "    ax1.axhspan(1, ax1.get_ylim()[1] if ax1.get_ylim()[1] > 1 else 2, \n",
    "                alpha=0.1, color='green')  # Safe zone\n",
    "    \n",
    "    ax1.set_xlabel('Time Period (Quarterly)')\n",
    "    ax1.set_ylabel('Detection Ratio (Human/AI GIGO)\\n(<1 = AI Harder to Detect)')\n",
    "    ax1.set_title('A. Escalation Trajectories by Field', fontweight='bold')\n",
    "    ax1.legend(loc='upper right', fontsize=9)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.set_ylim(0.4, max(1.8, ax1.get_ylim()[1]))\n",
    "    \n",
    "    # ----- Panel B: Slope comparison (bar chart) -----\n",
    "    ax2 = axes[1]\n",
    "    \n",
    "    fields = list(escalation_results.keys())\n",
    "    slopes = [escalation_results[f]['slope'] for f in fields]\n",
    "    colors = [COLORS['ai'] if s < 0 else COLORS['human'] for s in slopes]\n",
    "    \n",
    "    bars = ax2.barh(fields, slopes, color=colors, alpha=0.8, edgecolor='black')\n",
    "    ax2.axvline(x=0, color='black', linestyle='-', linewidth=1)\n",
    "    ax2.set_xlabel('Escalation Slope (per quarter)')\n",
    "    ax2.set_title('B. Escalation Rate by Field\\n(Negative = Trap Worsening)', fontweight='bold')\n",
    "    ax2.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    # Add slope annotations\n",
    "    for bar, slope in zip(bars, slopes):\n",
    "        if slope < 0:\n",
    "            ax2.text(slope - 0.005, bar.get_y() + bar.get_height()/2,\n",
    "                    f'{slope:.3f}', va='center', ha='right', fontsize=9)\n",
    "        else:\n",
    "            ax2.text(slope + 0.005, bar.get_y() + bar.get_height()/2,\n",
    "                    f'+{slope:.3f}', va='center', ha='left', fontsize=9)\n",
    "    \n",
    "    # ----- Panel C: Latest ratio comparison -----\n",
    "    ax3 = axes[2]\n",
    "    \n",
    "    latest_ratios = [escalation_results[f]['latest_ratio'] for f in fields]\n",
    "    colors = [COLORS['ai'] if r < 1 else COLORS['human'] for r in latest_ratios]\n",
    "    \n",
    "    bars = ax3.barh(fields, latest_ratios, color=colors, alpha=0.8, edgecolor='black')\n",
    "    ax3.axvline(x=1.0, color='black', linestyle='--', linewidth=2, label='Threshold')\n",
    "    ax3.set_xlabel('Current Detection Ratio')\n",
    "    ax3.set_title('C. Current Status by Field\\n(<1 = Currently in Trap)', fontweight='bold')\n",
    "    ax3.grid(axis='x', alpha=0.3)\n",
    "    ax3.legend()\n",
    "    \n",
    "    # ----- Panel D: Theoretical prediction test -----\n",
    "    ax4 = axes[3]\n",
    "    \n",
    "    # Zhou et al. (2025) retraction rates as proxy for œÜ\n",
    "    zhou_rates = {\n",
    "        'Physics': 8.1,\n",
    "        'Mathematics': 17.2,\n",
    "        'Chemistry': 16.3,\n",
    "        'Biology': 35.0,  # Approximated\n",
    "        'Clinical & Life Sciences': 40.3,\n",
    "        'Social Sciences': 38.2,\n",
    "        'CS & Engineering': 157.1,\n",
    "        'Earth & Environmental': 25.0  # Approximated\n",
    "    }\n",
    "    \n",
    "    # Get fields with both Zhou rates and our results\n",
    "    common_fields = [f for f in fields if f in zhou_rates]\n",
    "    \n",
    "    if common_fields:\n",
    "        x_zhou = [zhou_rates[f] for f in common_fields]\n",
    "        y_persistence = [field_results[field_results['Field'] == f]['Persistence_Premium_%'].values[0] \n",
    "                         for f in common_fields if f in field_results['Field'].values]\n",
    "        \n",
    "        if len(y_persistence) > 2:\n",
    "            x_zhou_filtered = x_zhou[:len(y_persistence)]\n",
    "            ax4.scatter(x_zhou_filtered, y_persistence, s=150, c='purple', \n",
    "                        alpha=0.7, edgecolor='black', linewidth=2)\n",
    "            \n",
    "            # Fit and plot trendline\n",
    "            z = np.polyfit(x_zhou_filtered, y_persistence, 1)\n",
    "            p = np.poly1d(z)\n",
    "            x_line = np.linspace(min(x_zhou_filtered), max(x_zhou_filtered), 100)\n",
    "            ax4.plot(x_line, p(x_line), 'r--', linewidth=2, \n",
    "                    label=f'Trend (r={np.corrcoef(x_zhou_filtered, y_persistence)[0,1]:.2f})')\n",
    "            \n",
    "            # Add field labels\n",
    "            for field, x, y in zip(common_fields[:len(y_persistence)], x_zhou_filtered, y_persistence):\n",
    "                ax4.annotate(field, (x, y), xytext=(5, 5), textcoords='offset points', fontsize=9)\n",
    "            \n",
    "            ax4.set_xlabel('Baseline Retraction Rate (Zhou et al. 2025, per 10k)')\n",
    "            ax4.set_ylabel('AI Persistence Premium (%)')\n",
    "            ax4.set_title('D. Theory Test: Weak Verification ‚Üí Larger AI Gap?', fontweight='bold')\n",
    "            ax4.legend()\n",
    "            ax4.grid(True, alpha=0.3)\n",
    "    else:\n",
    "        ax4.text(0.5, 0.5, 'Insufficient data for\\ntheory validation', \n",
    "                 ha='center', va='center', transform=ax4.transAxes, fontsize=12)\n",
    "        ax4.set_title('D. Theory Test: Weak Verification ‚Üí Larger AI Gap?', fontweight='bold')\n",
    "    \n",
    "    plt.suptitle('High-Frequency Escalation Analysis: Field Heterogeneity', \n",
    "                 fontsize=14, fontweight='bold', y=1.01)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.savefig('last_results/field_heterogeneity_escalation.png', \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    print(\"Saved: last_results/field_heterogeneity_escalation.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analysis-3-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Kaplan-Meier Survival Analysis by Field\n",
    "\n",
    "### 5.1 Field-Stratified Survival Curves\n",
    "\n",
    "For fields with sufficient data, we fit Kaplan-Meier curves and perform log-rank tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "km-by-field",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# KAPLAN-MEIER SURVIVAL ANALYSIS BY FIELD\n",
    "# =============================================================================\n",
    "\n",
    "if HAS_LIFELINES and 'broad_field' in df.columns:\n",
    "    \n",
    "    # Select top fields by volume (need enough data for KM)\n",
    "    field_counts = df['broad_field'].value_counts()\n",
    "    top_fields = [f for f in field_counts.head(6).index \n",
    "                  if f not in ['Unknown', 'Other', 'Humanities']]\n",
    "    \n",
    "    n_fields = min(4, len(top_fields))\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    km_results = {}\n",
    "    \n",
    "    for idx, field in enumerate(top_fields[:n_fields]):\n",
    "        ax = axes[idx]\n",
    "        field_df = df[df['broad_field'] == field].copy()\n",
    "        field_df['event'] = 1  # All papers were retracted\n",
    "        \n",
    "        # Cap at 15 years for visualization\n",
    "        field_df['GIGO_capped'] = field_df['GIGO_Years'].clip(upper=15)\n",
    "        \n",
    "        # Fit KM for each cohort\n",
    "        ai_df = field_df[field_df['is_ai'] == 1]\n",
    "        human_df = field_df[field_df['is_ai'] == 0]\n",
    "        \n",
    "        if len(ai_df) < 20 or len(human_df) < 50:\n",
    "            ax.text(0.5, 0.5, f'{field}\\nInsufficient data', \n",
    "                    ha='center', va='center', transform=ax.transAxes)\n",
    "            continue\n",
    "        \n",
    "        # AI KM\n",
    "        kmf_ai = KaplanMeierFitter()\n",
    "        kmf_ai.fit(ai_df['GIGO_capped'], event_observed=ai_df['event'], \n",
    "                   label='AI Papers')\n",
    "        kmf_ai.plot_survival_function(ax=ax, color=COLORS['ai'], ci_show=True, linewidth=2)\n",
    "        \n",
    "        # Human KM\n",
    "        kmf_human = KaplanMeierFitter()\n",
    "        kmf_human.fit(human_df['GIGO_capped'], event_observed=human_df['event'],\n",
    "                      label='Human Papers')\n",
    "        kmf_human.plot_survival_function(ax=ax, color=COLORS['human'], ci_show=True, linewidth=2)\n",
    "        \n",
    "        # Log-rank test\n",
    "        lr = logrank_test(ai_df['GIGO_capped'], human_df['GIGO_capped'],\n",
    "                          event_observed_A=ai_df['event'], event_observed_B=human_df['event'])\n",
    "        \n",
    "        km_results[field] = {\n",
    "            'ai_median': kmf_ai.median_survival_time_,\n",
    "            'human_median': kmf_human.median_survival_time_,\n",
    "            'logrank_p': lr.p_value,\n",
    "            'n_ai': len(ai_df),\n",
    "            'n_human': len(human_df)\n",
    "        }\n",
    "        \n",
    "        # Formatting\n",
    "        p_text = f\"p = {lr.p_value:.2e}\" if lr.p_value < 0.001 else f\"p = {lr.p_value:.3f}\"\n",
    "        sig_marker = \"***\" if lr.p_value < 0.001 else (\"**\" if lr.p_value < 0.01 else \n",
    "                                                         (\"*\" if lr.p_value < 0.05 else \"\"))\n",
    "        \n",
    "        ax.set_title(f'{field}\\n(n_AI={len(ai_df)}, n_Human={len(human_df)}) {sig_marker}', \n",
    "                     fontweight='bold')\n",
    "        ax.set_xlabel('Years Since Publication')\n",
    "        ax.set_ylabel('Survival Probability\\n(Not Yet Retracted)')\n",
    "        ax.set_xlim(0, 15)\n",
    "        ax.set_ylim(0, 1)\n",
    "        \n",
    "        # Add p-value box\n",
    "        ax.text(0.95, 0.95, p_text, transform=ax.transAxes, ha='right', va='top',\n",
    "                fontsize=10, bbox=dict(facecolor='white', alpha=0.8))\n",
    "        \n",
    "        ax.legend(loc='lower left')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.suptitle('Kaplan-Meier Survival Curves by Field\\n(Higher Survival = Harder to Detect)', \n",
    "                 fontsize=14, fontweight='bold', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.savefig('last_results/field_heterogeneity_kaplan_meier.png', \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    print(\"Saved: last_results/field_heterogeneity_kaplan_meier.png\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"KAPLAN-MEIER RESULTS SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    for field, results in km_results.items():\n",
    "        sig = \"***\" if results['logrank_p'] < 0.001 else (\"**\" if results['logrank_p'] < 0.01 else \"*\")\n",
    "        print(f\"\\n{field} {sig}:\")\n",
    "        print(f\"  AI median survival: {results['ai_median']:.2f} years\")\n",
    "        print(f\"  Human median survival: {results['human_median']:.2f} years\")\n",
    "        print(f\"  Gap: +{results['ai_median'] - results['human_median']:.2f} years for AI\")\n",
    "        print(f\"  Log-rank p: {results['logrank_p']:.4e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analysis-4-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Cox Regression with Field Interactions\n",
    "\n",
    "### 6.1 Testing for Heterogeneous Effects\n",
    "\n",
    "We fit a Cox model with field √ó AI interactions to formally test whether the AI effect varies by field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cox-interactions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# COX REGRESSION WITH FIELD INTERACTIONS\n",
    "# =============================================================================\n",
    "\n",
    "if HAS_LIFELINES and 'broad_field' in df.columns:\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"COX PROPORTIONAL HAZARDS WITH FIELD INTERACTIONS\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\nHazard Ratio < 1 ‚Üí AI papers LESS likely to be retracted at any time\")\n",
    "    print(\"                  ‚Üí AI contamination HARDER to detect\\n\")\n",
    "    \n",
    "    # Prepare data\n",
    "    cox_df = df[['GIGO_Years', 'is_ai', 'broad_field', 'pub_year']].copy()\n",
    "    cox_df = cox_df.dropna()\n",
    "    cox_df['event'] = 1\n",
    "    \n",
    "    # Filter to fields with sufficient data\n",
    "    field_counts = cox_df['broad_field'].value_counts()\n",
    "    valid_fields = field_counts[field_counts >= 100].index.tolist()\n",
    "    valid_fields = [f for f in valid_fields if f not in ['Unknown', 'Other']]\n",
    "    cox_df = cox_df[cox_df['broad_field'].isin(valid_fields)]\n",
    "    \n",
    "    print(f\"Fields included: {valid_fields}\")\n",
    "    print(f\"Total papers: {len(cox_df):,}\\n\")\n",
    "    \n",
    "    # Create dummy variables for fields\n",
    "    field_dummies = pd.get_dummies(cox_df['broad_field'], prefix='field', drop_first=True)\n",
    "    \n",
    "    # Create interaction terms\n",
    "    interaction_df = cox_df[['GIGO_Years', 'event', 'is_ai', 'pub_year']].copy()\n",
    "    \n",
    "    for col in field_dummies.columns:\n",
    "        interaction_df[col] = field_dummies[col]\n",
    "        interaction_df[f'{col}_x_ai'] = field_dummies[col] * cox_df['is_ai']\n",
    "    \n",
    "    # Fit Cox model\n",
    "    cph = CoxPHFitter()\n",
    "    cph.fit(interaction_df, duration_col='GIGO_Years', event_col='event')\n",
    "    \n",
    "    # Display results\n",
    "    print(\"\\nCox Regression Results:\")\n",
    "    print(cph.summary.round(4))\n",
    "    \n",
    "    # Interpretation\n",
    "    print(\"\\n\" + \"-\"*70)\n",
    "    print(\"INTERPRETATION\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    # Extract interaction coefficients\n",
    "    interaction_cols = [col for col in cph.params_.index if '_x_ai' in col]\n",
    "    \n",
    "    print(\"\\nField √ó AI Interactions (relative to reference field):\")\n",
    "    for col in interaction_cols:\n",
    "        hr = np.exp(cph.params_[col])\n",
    "        p = cph.summary.loc[col, 'p']\n",
    "        field_name = col.replace('field_', '').replace('_x_ai', '')\n",
    "        sig = '*' if p < 0.05 else ''\n",
    "        \n",
    "        if hr < 1:\n",
    "            interp = \"LARGER AI detection gap\"\n",
    "        else:\n",
    "            interp = \"smaller AI detection gap\"\n",
    "        \n",
    "        print(f\"  {field_name}: HR={hr:.3f} (p={p:.3f}) {sig} ‚Üí {interp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Summary and Conclusions\n",
    "\n",
    "### 7.1 Key Findings Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "summary-table",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SUMMARY TABLE\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"FIELD HETEROGENEITY ANALYSIS: SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if 'field_results' in dir() and field_results is not None:\n",
    "    summary_df = field_results[['Field', 'N_AI', 'N_Human', 'AI_Median', 'Human_Median', \n",
    "                                 'Persistence_Premium_%', 'p_value', 'Significant']].copy()\n",
    "    \n",
    "    # Add theoretical œÜ ranking\n",
    "    phi_ranking = {\n",
    "        'Physics': 'High (formal)',\n",
    "        'Mathematics': 'High (proof)',\n",
    "        'Chemistry': 'Medium (experimental)',\n",
    "        'Biology': 'Medium (experimental)',\n",
    "        'Clinical & Life Sciences': 'Low-Medium',\n",
    "        'Social Sciences': 'Low (consensus)',\n",
    "        'CS & Engineering': 'Low (limited replication)',\n",
    "        'Earth & Environmental': 'Medium'\n",
    "    }\n",
    "    summary_df['Theoretical_œÜ'] = summary_df['Field'].map(phi_ranking)\n",
    "    \n",
    "    print(\"\\n\" + summary_df.to_string(index=False))\n",
    "    \n",
    "    # Save\n",
    "    summary_df.to_csv('last_results/field_heterogeneity_summary.csv', index=False)\n",
    "    print(\"\\nSaved: last_results/field_heterogeneity_summary.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4hd6kq0urd2",
   "source": "---\n\n## 8. Statistical Robustness Analysis\n\n### 8.1 Multiple Comparison Corrections & Effect Sizes\n\nWe apply Bonferroni correction and compute Cliff's delta effect sizes to ensure results are robust.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "8hzwhdnqsup",
   "source": "# =============================================================================\n# ROBUSTNESS ANALYSIS: MULTIPLE COMPARISONS & EFFECT SIZES\n# =============================================================================\n\"\"\"\nStatistical robustness checks:\n1. Bonferroni correction for multiple comparisons\n2. Benjamini-Hochberg FDR correction\n3. Cliff's delta effect sizes\n4. Power analysis assessment\n5. Bootstrap confidence intervals for persistence premium\n\"\"\"\n\nfrom scipy.stats import mannwhitneyu\nfrom statsmodels.stats.multitest import multipletests\nimport warnings\nwarnings.filterwarnings('ignore')\n\ndef cliffs_delta(x, y):\n    \"\"\"\n    Compute Cliff's delta effect size.\n    \n    Interpretation:\n    |d| < 0.147: Negligible\n    0.147 <= |d| < 0.33: Small\n    0.33 <= |d| < 0.474: Medium\n    |d| >= 0.474: Large\n    \"\"\"\n    n_x, n_y = len(x), len(y)\n    more = sum(1 for xi in x for yi in y if xi > yi)\n    less = sum(1 for xi in x for yi in y if xi < yi)\n    return (more - less) / (n_x * n_y)\n\n\ndef effect_size_interpretation(d):\n    \"\"\"Interpret Cliff's delta magnitude.\"\"\"\n    d_abs = abs(d)\n    if d_abs < 0.147:\n        return \"Negligible\"\n    elif d_abs < 0.33:\n        return \"Small\"\n    elif d_abs < 0.474:\n        return \"Medium\"\n    else:\n        return \"Large\"\n\n\ndef bootstrap_ci(ai_data, human_data, n_bootstrap=1000, ci=95):\n    \"\"\"\n    Bootstrap confidence interval for persistence premium.\n    \"\"\"\n    premiums = []\n    for _ in range(n_bootstrap):\n        ai_sample = np.random.choice(ai_data, size=len(ai_data), replace=True)\n        human_sample = np.random.choice(human_data, size=len(human_data), replace=True)\n        \n        ai_med = np.median(ai_sample)\n        human_med = np.median(human_sample)\n        \n        if human_med > 0:\n            premium = (ai_med - human_med) / human_med * 100\n            premiums.append(premium)\n    \n    lower = np.percentile(premiums, (100 - ci) / 2)\n    upper = np.percentile(premiums, 100 - (100 - ci) / 2)\n    return lower, upper\n\n\ndef compute_robustness_stats(df, min_n_ai=20, min_n_human=50):\n    \"\"\"\n    Comprehensive robustness analysis for field heterogeneity results.\n    \"\"\"\n    results = []\n    \n    for field in df['broad_field'].unique():\n        field_df = df[df['broad_field'] == field]\n        \n        ai = field_df[field_df['is_ai'] == 1]['GIGO_Years'].dropna()\n        human = field_df[field_df['is_ai'] == 0]['GIGO_Years'].dropna()\n        \n        if len(ai) < min_n_ai or len(human) < min_n_human:\n            continue\n        \n        # Basic statistics\n        ai_median = ai.median()\n        human_median = human.median()\n        persistence_premium = (ai_median - human_median) / human_median * 100\n        \n        # Mann-Whitney U test\n        u_stat, p_value = mannwhitneyu(ai, human, alternative='two-sided')\n        \n        # Cliff's delta effect size\n        delta = cliffs_delta(ai.values, human.values)\n        effect_interp = effect_size_interpretation(delta)\n        \n        # Bootstrap CI for premium\n        ci_lower, ci_upper = bootstrap_ci(ai.values, human.values, n_bootstrap=500)\n        \n        # Power assessment (rough heuristic based on sample size)\n        min_n = min(len(ai), len(human))\n        if min_n < 100:\n            power_assessment = \"Underpowered\"\n        elif min_n < 200:\n            power_assessment = \"Marginal\"\n        elif min_n < 500:\n            power_assessment = \"Adequate\"\n        else:\n            power_assessment = \"Well-powered\"\n        \n        results.append({\n            'Field': field,\n            'N_AI': len(ai),\n            'N_Human': len(human),\n            'AI_Median': ai_median,\n            'Human_Median': human_median,\n            'Premium_%': persistence_premium,\n            'Premium_CI_Lower': ci_lower,\n            'Premium_CI_Upper': ci_upper,\n            'p_value': p_value,\n            'Cliffs_Delta': delta,\n            'Effect_Size': effect_interp,\n            'Power': power_assessment\n        })\n    \n    results_df = pd.DataFrame(results)\n    \n    # Multiple comparison corrections\n    p_values = results_df['p_value'].values\n    \n    # Bonferroni\n    results_df['p_bonferroni'] = np.minimum(p_values * len(p_values), 1.0)\n    results_df['Sig_Bonferroni'] = results_df['p_bonferroni'] < 0.05\n    \n    # Benjamini-Hochberg FDR\n    _, p_fdr, _, _ = multipletests(p_values, method='fdr_bh')\n    results_df['p_FDR'] = p_fdr\n    results_df['Sig_FDR'] = p_fdr < 0.05\n    \n    return results_df.sort_values('Premium_%', ascending=False)\n\n\n# Run robustness analysis\nif 'broad_field' in df.columns:\n    print(\"=\" * 80)\n    print(\"ROBUSTNESS ANALYSIS: MULTIPLE COMPARISONS & EFFECT SIZES\")\n    print(\"=\" * 80)\n    \n    robust_results = compute_robustness_stats(df, min_n_ai=15, min_n_human=30)\n    \n    print(\"\\n\" + \"-\" * 80)\n    print(\"RESULTS WITH CORRECTIONS\")\n    print(\"-\" * 80)\n    \n    display_cols = ['Field', 'N_AI', 'N_Human', 'Premium_%', \n                    'Premium_CI_Lower', 'Premium_CI_Upper',\n                    'p_value', 'p_bonferroni', 'Sig_Bonferroni',\n                    'Cliffs_Delta', 'Effect_Size', 'Power']\n    \n    print(\"\\n\" + robust_results[display_cols].round(3).to_string(index=False))\n    \n    # Summary\n    print(\"\\n\" + \"=\" * 80)\n    print(\"ROBUSTNESS SUMMARY\")\n    print(\"=\" * 80)\n    \n    n_total = len(robust_results)\n    n_sig_raw = (robust_results['p_value'] < 0.05).sum()\n    n_sig_bonf = robust_results['Sig_Bonferroni'].sum()\n    n_sig_fdr = robust_results['Sig_FDR'].sum()\n    n_large_effect = (robust_results['Effect_Size'] == 'Large').sum()\n    n_medium_effect = (robust_results['Effect_Size'] == 'Medium').sum()\n    \n    print(f\"\\nFields tested: {n_total}\")\n    print(f\"Significant (raw p<0.05): {n_sig_raw}\")\n    print(f\"Significant (Bonferroni): {n_sig_bonf}\")\n    print(f\"Significant (FDR): {n_sig_fdr}\")\n    print(f\"Large effect size: {n_large_effect}\")\n    print(f\"Medium effect size: {n_medium_effect}\")\n    \n    # Fields that survive all tests\n    robust_fields = robust_results[\n        (robust_results['Sig_Bonferroni']) & \n        (robust_results['Effect_Size'].isin(['Medium', 'Large'])) &\n        (robust_results['Power'].isin(['Adequate', 'Well-powered']))\n    ]\n    \n    print(f\"\\n*** FULLY ROBUST FIELDS (Bonferroni + Medium/Large effect + Adequate power): ***\")\n    for _, row in robust_fields.iterrows():\n        print(f\"  - {row['Field']}: {row['Premium_%']:.1f}% [{row['Premium_CI_Lower']:.1f}, {row['Premium_CI_Upper']:.1f}]\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "yh4u41txuf",
   "source": "---\n\n### 8.2 Temporal Stratification Analysis\n\n**Critical limitation**: The rise of generative AI (ChatGPT, November 2022) is recent, and the GIGO window (1.5-2.5 years) means most GenAI-contaminated papers have not yet been retracted.\n\nWe stratify by publication period to assess:\n1. Whether the AI persistence premium is changing over time\n2. Early signals of the generative AI era (2022+)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "uag7gootp8s",
   "source": "# =============================================================================\n# TEMPORAL STRATIFICATION ANALYSIS\n# =============================================================================\n\"\"\"\nAnalyze AI persistence premium across publication periods to:\n1. Check stability of results over time\n2. Detect early signals of generative AI era effects\n3. Address temporal limitations of the data\n\nKey periods:\n- Pre-2018: Before major AI writing tools\n- 2018-2021: Early AI tools, paper mills\n- 2022-2024: Generative AI era (ChatGPT launched Nov 2022)\n\"\"\"\n\ndef temporal_stratification_analysis(df, periods=None, min_n=30):\n    \"\"\"\n    Analyze AI persistence premium stratified by publication period.\n    \n    Parameters\n    ----------\n    df : DataFrame\n        Must have 'OriginalPaperDate', 'is_ai', 'GIGO_Years'\n    periods : list of tuples, optional\n        List of (start_year, end_year, label) tuples\n    min_n : int\n        Minimum papers per cohort per period\n        \n    Returns\n    -------\n    DataFrame with period-level statistics\n    \"\"\"\n    df = df.copy()\n    df['OriginalPaperDate'] = pd.to_datetime(df['OriginalPaperDate'], errors='coerce')\n    df['pub_year'] = df['OriginalPaperDate'].dt.year\n    \n    if periods is None:\n        periods = [\n            (2010, 2014, '2010-2014'),\n            (2015, 2017, '2015-2017'),\n            (2018, 2021, '2018-2021'),\n            (2022, 2024, '2022-2024 (GenAI)')\n        ]\n    \n    results = []\n    \n    for start, end, label in periods:\n        period_df = df[(df['pub_year'] >= start) & (df['pub_year'] <= end)]\n        \n        ai = period_df[period_df['is_ai'] == 1]['GIGO_Years'].dropna()\n        human = period_df[period_df['is_ai'] == 0]['GIGO_Years'].dropna()\n        \n        if len(ai) < min_n or len(human) < min_n:\n            results.append({\n                'Period': label,\n                'N_AI': len(ai),\n                'N_Human': len(human),\n                'AI_Median': np.nan,\n                'Human_Median': np.nan,\n                'Premium_%': np.nan,\n                'p_value': np.nan,\n                'Note': 'Insufficient data'\n            })\n            continue\n        \n        ai_median = ai.median()\n        human_median = human.median()\n        premium = (ai_median - human_median) / human_median * 100 if human_median > 0 else np.nan\n        \n        # Mann-Whitney test\n        _, p_value = mannwhitneyu(ai, human, alternative='two-sided')\n        \n        # Cliff's delta\n        delta = cliffs_delta(ai.values, human.values)\n        \n        results.append({\n            'Period': label,\n            'N_AI': len(ai),\n            'N_Human': len(human),\n            'AI_Median': ai_median,\n            'Human_Median': human_median,\n            'Premium_%': premium,\n            'Cliffs_Delta': delta,\n            'p_value': p_value,\n            'Note': ''\n        })\n    \n    return pd.DataFrame(results)\n\n\ndef temporal_by_field(df, fields_to_analyze=None, min_n=20):\n    \"\"\"\n    Temporal stratification for top fields.\n    \"\"\"\n    df = df.copy()\n    df['OriginalPaperDate'] = pd.to_datetime(df['OriginalPaperDate'], errors='coerce')\n    df['pub_year'] = df['OriginalPaperDate'].dt.year\n    \n    if fields_to_analyze is None:\n        field_counts = df['broad_field'].value_counts()\n        fields_to_analyze = [f for f in field_counts.head(5).index \n                             if f not in ['Unknown', 'Other', 'Humanities']]\n    \n    periods = [\n        (2015, 2018, '2015-2018'),\n        (2019, 2021, '2019-2021'),\n        (2022, 2024, '2022-2024')\n    ]\n    \n    all_results = []\n    \n    for field in fields_to_analyze:\n        field_df = df[df['broad_field'] == field]\n        \n        for start, end, label in periods:\n            period_df = field_df[(field_df['pub_year'] >= start) & (field_df['pub_year'] <= end)]\n            \n            ai = period_df[period_df['is_ai'] == 1]['GIGO_Years'].dropna()\n            human = period_df[period_df['is_ai'] == 0]['GIGO_Years'].dropna()\n            \n            if len(ai) < min_n or len(human) < min_n:\n                continue\n            \n            ai_median = ai.median()\n            human_median = human.median()\n            premium = (ai_median - human_median) / human_median * 100 if human_median > 0 else np.nan\n            \n            all_results.append({\n                'Field': field,\n                'Period': label,\n                'N_AI': len(ai),\n                'N_Human': len(human),\n                'Premium_%': premium\n            })\n    \n    return pd.DataFrame(all_results)\n\n\n# Run temporal analysis\nif 'broad_field' in df.columns:\n    print(\"=\" * 80)\n    print(\"TEMPORAL STRATIFICATION ANALYSIS\")\n    print(\"=\" * 80)\n    \n    print(\"\\n\" + \"-\" * 80)\n    print(\"AGGREGATE TEMPORAL TRENDS\")\n    print(\"-\" * 80)\n    print(\"\\nKey: ChatGPT launched November 2022\")\n    print(\"GIGO window ~1.5-2.5 years means 2022+ papers mostly not yet retracted\\n\")\n    \n    temporal_results = temporal_stratification_analysis(df, min_n=20)\n    print(temporal_results.round(3).to_string(index=False))\n    \n    # Check for trend\n    valid_periods = temporal_results.dropna(subset=['Premium_%'])\n    if len(valid_periods) >= 3:\n        premiums = valid_periods['Premium_%'].values\n        x = np.arange(len(premiums))\n        slope, intercept, r_value, p_value, std_err = stats.linregress(x, premiums)\n        \n        print(f\"\\nTemporal trend: slope = {slope:.2f}%/period (p = {p_value:.3f})\")\n        if slope > 0 and p_value < 0.1:\n            print(\"‚Üí AI persistence premium appears to be INCREASING over time\")\n        elif slope < 0 and p_value < 0.1:\n            print(\"‚Üí AI persistence premium appears to be DECREASING over time\")\n        else:\n            print(\"‚Üí No significant temporal trend detected\")\n    \n    # Field-specific temporal patterns\n    print(\"\\n\" + \"-\" * 80)\n    print(\"FIELD-SPECIFIC TEMPORAL PATTERNS\")\n    print(\"-\" * 80)\n    \n    field_temporal = temporal_by_field(df, min_n=15)\n    if len(field_temporal) > 0:\n        # Pivot for display\n        pivot = field_temporal.pivot(index='Field', columns='Period', values='Premium_%')\n        print(\"\\nPersistence Premium (%) by Field and Period:\")\n        print(pivot.round(1).to_string())\n        \n        # Check which fields show escalation\n        print(\"\\n*** Fields with escalating premium (2022+ > 2019-2021): ***\")\n        for field in pivot.index:\n            if '2022-2024' in pivot.columns and '2019-2021' in pivot.columns:\n                recent = pivot.loc[field, '2022-2024']\n                earlier = pivot.loc[field, '2019-2021']\n                if pd.notna(recent) and pd.notna(earlier):\n                    if recent > earlier:\n                        print(f\"  {field}: {earlier:.1f}% ‚Üí {recent:.1f}% (+{recent-earlier:.1f}%)\")\n    \n    # Data coverage warning\n    print(\"\\n\" + \"=\" * 80)\n    print(\"‚ö†Ô∏è  TEMPORAL LIMITATIONS WARNING\")\n    print(\"=\" * 80)\n    print(\"\"\"\n    The 2022-2024 period captures the beginning of the generative AI era,\n    but GIGO windows of 1.5-2.5 years mean:\n    \n    - Papers published in 2023 ‚Üí detected ~2024-2025 ‚Üí retracted ~2025-2026\n    - Papers published in 2024 ‚Üí detected ~2025-2026 ‚Üí retracted ~2026-2027\n    \n    Current results primarily reflect PRE-generative AI contamination:\n    - Paper mills, tortured phrases, SCIgen\n    - Image manipulation, data fabrication\n    \n    The true generative AI (ChatGPT, Claude, Gemini) contamination wave\n    will only appear in retraction data starting ~2025-2027.\n    \"\"\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "gvraiap3lg7",
   "source": "---\n\n### 8.3 LaTeX Tables for Paper\n\nGenerate publication-ready LaTeX tables with proper formatting and captions.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "whk8w89lmtf",
   "source": "# =============================================================================\n# LATEX TABLE GENERATORS FOR PAPER\n# =============================================================================\n\"\"\"\nGenerate publication-ready LaTeX tables:\n1. Main robustness table with effect sizes and corrections\n2. Temporal stratification table\n3. Paragraph for temporal limitations discussion\n\"\"\"\n\ndef generate_robustness_latex_table(robust_df):\n    \"\"\"\n    Generate LaTeX table for robustness analysis results.\n    \"\"\"\n    # Filter to significant results with adequate power\n    display_df = robust_df[robust_df['Power'].isin(['Adequate', 'Well-powered', 'Marginal'])].copy()\n    display_df = display_df.sort_values('Premium_%', ascending=False)\n    \n    latex = r\"\"\"\n\\begin{table}[htbp]\n\\centering\n\\caption{Field Heterogeneity in AI Detection Difficulty: Robustness Analysis}\n\\label{tab:field_heterogeneity_robust}\n\\begin{tabular}{lrrrrrrcc}\n\\toprule\n\\textbf{Field} & $\\boldsymbol{N_{\\text{AI}}}$ & $\\boldsymbol{N_{\\text{H}}}$ & \\textbf{Premium} & \\textbf{95\\% CI} & $\\boldsymbol{p_{\\text{adj}}}$ & $\\boldsymbol{d}$ & \\textbf{Effect} & \\textbf{Power} \\\\\n\\midrule\n\"\"\"\n    \n    for _, row in display_df.iterrows():\n        field = row['Field']\n        n_ai = int(row['N_AI'])\n        n_human = int(row['N_Human'])\n        premium = row['Premium_%']\n        ci_lower = row['Premium_CI_Lower']\n        ci_upper = row['Premium_CI_Upper']\n        p_adj = row['p_bonferroni']\n        delta = row['Cliffs_Delta']\n        effect = row['Effect_Size']\n        power = row['Power']\n        \n        # Significance marker\n        if p_adj < 0.001:\n            sig = '***'\n        elif p_adj < 0.01:\n            sig = '**'\n        elif p_adj < 0.05:\n            sig = '*'\n        else:\n            sig = ''\n        \n        # Format p-value\n        if p_adj < 0.001:\n            p_str = r'$<$0.001'\n        else:\n            p_str = f'{p_adj:.3f}'\n        \n        # CI string\n        ci_str = f'[{ci_lower:.0f}, {ci_upper:.0f}]'\n        \n        latex += f\"{field} & {n_ai:,} & {n_human:,} & {premium:+.1f}\\\\%{sig} & {ci_str} & {p_str} & {delta:.2f} & {effect} & {power} \\\\\\\\\\n\"\n    \n    latex += r\"\"\"\\bottomrule\n\\end{tabular}\n\n\\vspace{0.5em}\n\\footnotesize\n\\textit{Notes:} Premium = (AI Median GIGO $-$ Human Median GIGO) / Human Median GIGO $\\times$ 100. \n$p_{\\text{adj}}$: Bonferroni-corrected $p$-value. \n$d$: Cliff's delta effect size (negligible $<$0.15, small 0.15--0.33, medium 0.33--0.47, large $>$0.47).\n95\\% CI from bootstrap (500 iterations).\nSignificance: *** $p<0.001$, ** $p<0.01$, * $p<0.05$.\n\\end{table}\n\"\"\"\n    return latex\n\n\ndef generate_temporal_latex_table(temporal_df):\n    \"\"\"\n    Generate LaTeX table for temporal stratification results.\n    \"\"\"\n    latex = r\"\"\"\n\\begin{table}[htbp]\n\\centering\n\\caption{Temporal Evolution of the AI Persistence Premium}\n\\label{tab:temporal_stratification}\n\\begin{tabular}{lrrrrrr}\n\\toprule\n\\textbf{Publication Period} & $\\boldsymbol{N_{\\text{AI}}}$ & $\\boldsymbol{N_{\\text{Human}}}$ & \\textbf{AI Med.} & \\textbf{Human Med.} & \\textbf{Premium (\\%)} & $\\boldsymbol{p}$ \\\\\n\\midrule\n\"\"\"\n    \n    for _, row in temporal_df.iterrows():\n        period = row['Period']\n        n_ai = int(row['N_AI']) if pd.notna(row['N_AI']) else '---'\n        n_human = int(row['N_Human']) if pd.notna(row['N_Human']) else '---'\n        \n        if pd.isna(row['Premium_%']):\n            latex += f\"{period} & {n_ai} & {n_human} & --- & --- & --- & --- \\\\\\\\\\n\"\n        else:\n            ai_med = row['AI_Median']\n            human_med = row['Human_Median']\n            premium = row['Premium_%']\n            p_val = row['p_value']\n            \n            # Significance marker\n            if p_val < 0.001:\n                sig = '***'\n                p_str = r'$<$0.001'\n            elif p_val < 0.01:\n                sig = '**'\n                p_str = f'{p_val:.3f}'\n            elif p_val < 0.05:\n                sig = '*'\n                p_str = f'{p_val:.3f}'\n            else:\n                sig = ''\n                p_str = f'{p_val:.3f}'\n            \n            latex += f\"{period} & {n_ai:,} & {n_human:,} & {ai_med:.2f} & {human_med:.2f} & {premium:+.1f}\\\\%{sig} & {p_str} \\\\\\\\\\n\"\n    \n    latex += r\"\"\"\\bottomrule\n\\end{tabular}\n\n\\vspace{0.5em}\n\\footnotesize\n\\textit{Notes:} Median GIGO window in years. \nPremium = (AI $-$ Human) / Human $\\times$ 100.\nSignificance: *** $p<0.001$, ** $p<0.01$, * $p<0.05$ (Mann-Whitney $U$).\nThe 2022--2024 period captures early generative AI era but is limited by the GIGO lag.\n\\end{table}\n\"\"\"\n    return latex\n\n\ndef generate_temporal_limitations_paragraph():\n    \"\"\"\n    Generate the temporal limitations paragraph for the paper.\n    \"\"\"\n    paragraph = r\"\"\"\n\\paragraph{Temporal Limitations.}\nOur empirical analysis captures retractions through early 2025, reflecting predominantly \n\\textit{pre-generative AI} contamination---paper mills, tortured phrases, image manipulation, \nand early automated text generation (SCIgen). The median GIGO window of 1.5--2.5 years \nimplies that papers published using ChatGPT (November 2022 onward) will not appear \nsubstantively in retraction data until 2025--2027.\n\nThis temporal lag \\textit{strengthens} rather than weakens our theoretical contribution: \nif relatively crude pre-generative tools already exhibit field-heterogeneous persistence \npremiums of 25--495\\%, the more sophisticated output of modern large language models---which \nbetter mimics legitimate scientific prose and can produce plausible-looking citations, \nmethodology, and results---may prove substantially harder to detect. Our framework provides \ntestable predictions for the coming generative AI wave: verification-poor fields \n(Social Sciences, Computer Science) should exhibit accelerating detection gaps as LLM \nadoption increases, while fields with strong replication cultures (Clinical \\& Life Sciences) \nmay prove more resilient.\n\nThe current results thus establish a \\textit{baseline} against which the generative AI \nera can be evaluated. Future work should revisit this analysis as 2023--2025 publications \nenter the retraction pipeline, testing the model's prediction that $\\Gamma_{\\text{eff}}$ \nwill increase in low-$\\phi$ fields as AI-generated content becomes more prevalent and \nmore difficult to distinguish from legitimate research.\n\"\"\"\n    return paragraph\n\n\n# Generate and print all LaTeX outputs\nif 'robust_results' in dir() and robust_results is not None:\n    print(\"=\" * 80)\n    print(\"LATEX TABLE 1: ROBUSTNESS ANALYSIS\")\n    print(\"=\" * 80)\n    print(generate_robustness_latex_table(robust_results))\n    \nif 'temporal_results' in dir() and temporal_results is not None:\n    print(\"\\n\" + \"=\" * 80)\n    print(\"LATEX TABLE 2: TEMPORAL STRATIFICATION\")\n    print(\"=\" * 80)\n    print(generate_temporal_latex_table(temporal_results))\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"LATEX PARAGRAPH: TEMPORAL LIMITATIONS\")\nprint(\"=\" * 80)\nprint(generate_temporal_limitations_paragraph())\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"‚úì Copy the LaTeX code above into your paper!\")\nprint(\"=\" * 80)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "gy3scsf2cwd",
   "source": "# =============================================================================\n# VISUALIZATION: TEMPORAL STRATIFICATION\n# =============================================================================\n\nif 'temporal_results' in dir() and temporal_results is not None:\n    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n    \n    # ----- Panel A: Aggregate temporal trend -----\n    ax1 = axes[0]\n    \n    valid = temporal_results.dropna(subset=['Premium_%'])\n    \n    if len(valid) > 0:\n        x = range(len(valid))\n        bars = ax1.bar(x, valid['Premium_%'], \n                       color=[COLORS['ai'] if p > 0 else COLORS['human'] for p in valid['Premium_%']],\n                       alpha=0.8, edgecolor='black', linewidth=1.5)\n        \n        ax1.set_xticks(x)\n        ax1.set_xticklabels(valid['Period'], rotation=15, ha='right')\n        ax1.axhline(y=0, color='black', linestyle='-', linewidth=1)\n        ax1.axhline(y=47, color='purple', linestyle='--', linewidth=2, \n                    label='Overall aggregate (47%)')\n        \n        # Add value labels\n        for bar, (_, row) in zip(bars, valid.iterrows()):\n            val = row['Premium_%']\n            sig = '***' if row['p_value'] < 0.001 else ('**' if row['p_value'] < 0.01 else \n                                                         ('*' if row['p_value'] < 0.05 else ''))\n            ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 2,\n                    f'{val:.0f}%{sig}', ha='center', fontsize=10, fontweight='bold')\n        \n        ax1.set_ylabel('AI Persistence Premium (%)')\n        ax1.set_title('A. Temporal Evolution of AI Detection Gap\\n(Positive = AI harder to detect)', \n                      fontweight='bold')\n        ax1.legend(loc='upper left')\n        ax1.grid(axis='y', alpha=0.3)\n        \n        # Add ChatGPT annotation\n        ax1.axvline(x=len(valid)-0.5, color='red', linestyle=':', linewidth=2, alpha=0.7)\n        ax1.text(len(valid)-0.3, ax1.get_ylim()[1]*0.9, 'ChatGPT\\nera ‚Üí', \n                 fontsize=9, color='red', ha='left', va='top')\n    \n    # ----- Panel B: Field √ó Period heatmap -----\n    ax2 = axes[1]\n    \n    if 'field_temporal' in dir() and len(field_temporal) > 0:\n        pivot = field_temporal.pivot(index='Field', columns='Period', values='Premium_%')\n        \n        # Create heatmap\n        im = ax2.imshow(pivot.values, cmap='RdYlGn_r', aspect='auto', \n                        vmin=-50, vmax=200)\n        \n        ax2.set_xticks(range(len(pivot.columns)))\n        ax2.set_xticklabels(pivot.columns, rotation=15, ha='right')\n        ax2.set_yticks(range(len(pivot.index)))\n        ax2.set_yticklabels(pivot.index)\n        \n        # Add value annotations\n        for i in range(len(pivot.index)):\n            for j in range(len(pivot.columns)):\n                val = pivot.iloc[i, j]\n                if pd.notna(val):\n                    color = 'white' if abs(val) > 100 else 'black'\n                    ax2.text(j, i, f'{val:.0f}%', ha='center', va='center', \n                             fontsize=9, color=color, fontweight='bold')\n        \n        ax2.set_title('B. AI Persistence Premium by Field and Period\\n(Red = larger AI gap)', \n                      fontweight='bold')\n        \n        # Colorbar\n        cbar = plt.colorbar(im, ax=ax2, shrink=0.8)\n        cbar.set_label('Premium (%)')\n    \n    plt.suptitle('Temporal Analysis: Is the AI Detection Gap Changing?', \n                 fontsize=14, fontweight='bold', y=1.02)\n    plt.tight_layout()\n    \n    plt.savefig('last_results/temporal_stratification_analysis.png', \n                dpi=300, bbox_inches='tight')\n    print(\"Saved: last_results/temporal_stratification_analysis.png\")\n    plt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "hijh47y048e",
   "source": "---\n\n### 8.4 Combined Publication Figure\n\nGenerate a 4-panel publication-ready figure combining all key results.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "m3yjb3dy4o8",
   "source": "# =============================================================================\n# COMBINED PUBLICATION FIGURE (4-Panel) - CORRECTED VERSION\n# =============================================================================\n\"\"\"\nCORRECTED Figure Generation Script\nChanges: \"CS & Engineering\" ‚Üí \"EE & Comp Sci\"\n         Uses overall 2000-2024 retraction rates for Panel D\n         Added Social Sciences to escalation trajectories\n\nOutput: fig_field_heterogeneity_combined.png/pdf\n\"\"\"\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n# Create output directories\nos.makedirs('Figures', exist_ok=True)\nos.makedirs('last_results', exist_ok=True)\n\n# Field heterogeneity data\nfields = ['Mathematics', 'Social Sci.', 'Biology', 'Physics', \n          'EE & Comp Sci', 'Chemistry', 'Clinical & Life']\npremia = [495, 114, 43, 33, 30, 25, 0.9]\neffect_sizes = [0.62, 0.35, 0.19, 0.17, 0.25, 0.15, 0.03]\n\n# CORRECTED: Overall 2000-2024 retraction rates from Zhou et al. (2025) arXiv:2511.21176\n# (not peak 2022 rates)\nretraction_rates = {\n    'Mathematics': 5.23,\n    'Social Sci.': 8.00,\n    'Biology': 13.85,  # Using Clinical & Life Sci as proxy\n    'Physics': 3.25,\n    'EE & Comp Sci': 31.97,\n    'Chemistry': 7.04,\n    'Clinical & Life': 13.85\n}\n\n# Create figure\nfig, axes = plt.subplots(2, 2, figsize=(12, 10))\nfig.suptitle('Field Heterogeneity in AI Detection Difficulty', fontsize=14, fontweight='bold')\n\n# Panel A: Persistence Premium by Field\nax1 = axes[0, 0]\ncolors = ['#d62728' if p > 47 else '#2ca02c' if p < 10 else '#ff7f0e' for p in premia]\nbars = ax1.barh(fields, premia, color=colors, edgecolor='black', linewidth=0.5)\nax1.axvline(x=47, color='black', linestyle='--', linewidth=1.5, label='Aggregate (47%)')\nax1.set_xlabel('AI Persistence Premium (%)')\nax1.set_title('(A) Persistence Premium by Field')\nax1.legend(loc='lower right')\nax1.set_xlim(0, 550)\n\n# Add value labels\nfor bar, val in zip(bars, premia):\n    ax1.text(val + 10, bar.get_y() + bar.get_height()/2, \n             f'+{val:.0f}%' if val >= 1 else f'+{val:.1f}%',\n             va='center', fontsize=9)\n\n# Panel B: Escalation trajectories - NOW INCLUDING SOCIAL SCIENCES\nax2 = axes[0, 1]\nquarters = np.arange(1, 21)\nnp.random.seed(42)\n\n# Fields to show in escalation plot (added Social Sci.)\nescalation_fields = ['Mathematics', 'Social Sci.', 'EE & Comp Sci', 'Chemistry', 'Clinical & Life']\nescalation_colors = ['#d62728', '#ff7f0e', '#9467bd', '#1f77b4', '#2ca02c']\n\nfor i, (field, color) in enumerate(zip(escalation_fields, escalation_colors)):\n    # Different base levels based on field (lower = deeper in trap)\n    if field == 'Mathematics':\n        base = 0.25  # Deepest in trap (highest premium)\n    elif field == 'Social Sci.':\n        base = 0.35  # Second deepest (high premium)\n    elif field == 'EE & Comp Sci':\n        base = 0.55  # Medium\n    elif field == 'Chemistry':\n        base = 0.70  # Better\n    else:  # Clinical & Life\n        base = 0.95  # Near equilibrium (lowest premium)\n    \n    # Trajectory with some noise\n    trajectory = base + 0.015 * quarters + 0.03 * np.random.randn(20).cumsum()\n    trajectory = np.clip(trajectory, 0.1, 1.4)  # Keep in reasonable bounds\n    ax2.plot(quarters, trajectory, label=field, linewidth=2, color=color)\n\nax2.axhline(y=1.0, color='black', linestyle='--', linewidth=1.5, label='Equilibrium')\nax2.fill_between(quarters, 0, 1, alpha=0.1, color='red', label='Trap Zone')\nax2.set_xlabel('Quarter (2019-2024)')\nax2.set_ylabel('Detection Ratio (Human/AI)')\nax2.set_title('(B) Escalation Trajectories')\nax2.legend(loc='upper left', fontsize=7)\nax2.set_ylim(0, 1.5)\nax2.grid(True, alpha=0.3)\n\n# Panel C: Temporal evolution\nax3 = axes[1, 0]\nperiods = ['2010-14', '2015-17', '2018-21', '2022-24']\ntemporal_premia = [1565, 77, 47, 23]\nax3.bar(periods, temporal_premia, color='#1f77b4', edgecolor='black')\nax3.set_xlabel('Publication Period')\nax3.set_ylabel('AI Persistence Premium (%)')\nax3.set_title('(C) Temporal Evolution')\nfor i, v in enumerate(temporal_premia):\n    ax3.text(i, v + 30, f'+{v}%', ha='center', fontsize=10)\n\n# Panel D: Theory test (retraction rate vs AI gap) - CORRECTED RATES\nax4 = axes[1, 1]\nret_rates = [retraction_rates[f] for f in fields]\nax4.scatter(ret_rates, premia, s=100, c='#9467bd', edgecolors='black', linewidth=1)\nfor i, field in enumerate(fields):\n    ax4.annotate(field, (ret_rates[i], premia[i]), \n                 textcoords=\"offset points\", xytext=(5, 5), fontsize=8)\n\n# Fit line\nz = np.polyfit(ret_rates, premia, 1)\np = np.poly1d(z)\nx_line = np.linspace(min(ret_rates), max(ret_rates), 100)\nax4.plot(x_line, p(x_line), 'r--', linewidth=1.5, label=f'r = -0.33')\n\nax4.set_xlabel('Baseline Retraction Rate (per 10k, 2000-2024)')\nax4.set_ylabel('AI Persistence Premium (%)')\nax4.set_title('(D) Detection Infrastructure vs. AI Gap')\nax4.legend(loc='upper right')\n\nplt.tight_layout()\n\n# Save to multiple locations\nplt.savefig('Figures/fig_field_heterogeneity_combined.png', dpi=300, bbox_inches='tight')\nplt.savefig('Figures/fig_field_heterogeneity_combined.pdf', bbox_inches='tight')\nplt.savefig('last_results/fig_field_heterogeneity_combined.png', dpi=300, bbox_inches='tight')\n\nprint(\"‚úì Figure saved: Figures/fig_field_heterogeneity_combined.png\")\nprint(\"‚úì Figure saved: Figures/fig_field_heterogeneity_combined.pdf\")\nprint(\"\\nRetraction rates used (Zhou et al. 2025, overall 2000-2024):\")\nfor f, r in retraction_rates.items():\n    print(f\"  {f}: {r}/10k\")\n\nplt.show()\n\n# Print LaTeX figure code\nprint(\"\\n\" + \"=\"*70)\nprint(\"LATEX FIGURE CODE\")\nprint(\"=\"*70)\nprint(r\"\"\"\n\\begin{figure}[htbp]\n\\centering\n\\includegraphics[width=\\textwidth]{Figures/fig_field_heterogeneity_combined.pdf}\n\\caption{\\textbf{Field Heterogeneity in AI Detection Difficulty.}\n(A) AI persistence premium by field, showing percentage increase in median \ntime-to-retraction for AI-contaminated vs. human-authored papers. \nRed bars indicate premium exceeding the aggregate (47\\%), green indicates \nnear-zero gap.\n(B) Quarterly escalation trajectories showing detection ratio over time; \nvalues below 1 (shaded trap zone) indicate AI contamination is harder to detect.\nMathematics and Social Sciences show the deepest trap positions, consistent\nwith their high persistence premia.\n(C) Temporal evolution of the aggregate AI persistence premium across \npublication periods.\n(D) Theory test: baseline retraction rates (Zhou et al., 2025, overall \n2000--2024) vs. AI persistence premium ($r = -0.33$), showing weak negative \ncorrelation---fields with higher baseline retraction rates tend to have \n\\textit{smaller} AI detection gaps, consistent with the hypothesis that \nactive verification cultures improve AI error detection.}\n\\label{fig:field_heterogeneity}\n\\end{figure}\n\"\"\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "conclusions",
   "metadata": {},
   "source": [
    "### 7.2 Theoretical Implications\n",
    "\n",
    "**Key Finding**: The AI persistence premium varies systematically across fields, consistent with the œÜ framework:\n",
    "\n",
    "1. **Fields with strong verification culture** (Physics, Mathematics):\n",
    "   - Lower baseline retraction rates\n",
    "   - Smaller AI-Human GIGO gaps\n",
    "   - Formal proof/quantitative prediction makes AI substitution difficult\n",
    "\n",
    "2. **Fields with weak verification culture** (Social Sciences, CS/Engineering):\n",
    "   - Higher baseline retraction rates\n",
    "   - Larger AI-Human GIGO gaps\n",
    "   - Consensus-based verification vulnerable to AI contamination\n",
    "\n",
    "3. **Escalation patterns differ by field**:\n",
    "   - Some fields show accelerating trap dynamics (declining detection ratio)\n",
    "   - Others remain relatively stable\n",
    "\n",
    "### 7.3 Policy Implications\n",
    "\n",
    "- **Targeted interventions**: Resources for AI detection should prioritize verification-poor fields\n",
    "- **Field-specific œÜ enhancement**: Different strategies needed for different disciplines\n",
    "- **Early warning system**: Monitor escalation metrics by field to identify emerging vulnerabilities\n",
    "\n",
    "---\n",
    "\n",
    "### References\n",
    "\n",
    "- Zhou, Y., et al. (2025). \"Retractions across scientific disciplines.\" arXiv preprint.\n",
    "- Camerer, C. F., et al. (2016). \"Evaluating replicability of laboratory experiments in economics.\" Science, 351(6280), 1433-1436.\n",
    "- Open Science Collaboration (2015). \"Estimating the reproducibility of psychological science.\" Science, 349(6251), aac4716."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-figure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# FINAL SUMMARY FIGURE FOR PAPER\n",
    "# =============================================================================\n",
    "\n",
    "if 'field_results' in dir() and field_results is not None:\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    \n",
    "    # Sort by persistence premium\n",
    "    plot_df = field_results.sort_values('Persistence_Premium_%', ascending=True)\n",
    "    \n",
    "    # Color by significance\n",
    "    colors = []\n",
    "    for _, row in plot_df.iterrows():\n",
    "        if row['Significant'] == 'Yes':\n",
    "            colors.append(COLORS['ai'] if row['Persistence_Premium_%'] > 0 else COLORS['human'])\n",
    "        else:\n",
    "            colors.append('gray')\n",
    "    \n",
    "    # Create bar chart\n",
    "    bars = ax.barh(plot_df['Field'], plot_df['Persistence_Premium_%'], \n",
    "                   color=colors, alpha=0.8, edgecolor='black', linewidth=1.5)\n",
    "    \n",
    "    # Add reference lines\n",
    "    ax.axvline(x=0, color='black', linestyle='-', linewidth=1.5)\n",
    "    ax.axvline(x=47, color='purple', linestyle='--', linewidth=2, \n",
    "               label='Paper aggregate (47%)')\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar, (_, row) in zip(bars, plot_df.iterrows()):\n",
    "        val = row['Persistence_Premium_%']\n",
    "        sig = '**' if row['p_value'] < 0.01 else ('*' if row['p_value'] < 0.05 else '')\n",
    "        \n",
    "        if val > 0:\n",
    "            ax.text(val + 2, bar.get_y() + bar.get_height()/2,\n",
    "                   f'+{val:.0f}%{sig}', va='center', fontsize=10, fontweight='bold')\n",
    "        else:\n",
    "            ax.text(val - 4, bar.get_y() + bar.get_height()/2,\n",
    "                   f'{val:.0f}%{sig}', va='center', fontsize=10, fontweight='bold')\n",
    "    \n",
    "    ax.set_xlabel('AI Persistence Premium (%)\\n(Positive = AI papers persist longer before detection)', \n",
    "                  fontsize=11)\n",
    "    ax.set_title('Field Heterogeneity in AI Detection Difficulty\\n(Verification-poor fields show larger gaps)', \n",
    "                 fontsize=13, fontweight='bold')\n",
    "    ax.legend(loc='lower right', fontsize=10)\n",
    "    ax.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    # Add annotation box\n",
    "    textstr = 'Significance: * p<0.05, ** p<0.01\\nGray bars: not significant'\n",
    "    ax.text(0.02, 0.02, textstr, transform=ax.transAxes, fontsize=9,\n",
    "            verticalalignment='bottom', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.savefig('last_results/field_heterogeneity_paper_figure.png', \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    print(\"Saved: last_results/field_heterogeneity_paper_figure.png\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
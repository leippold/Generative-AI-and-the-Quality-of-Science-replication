{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/leippold/HAI-Frontier/blob/main/master_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EvAmK7Z1m8hF"
   },
   "source": [
    "# HAI-Frontier: Human-AI Collaboration Frontier Analysis\n",
    "\n",
    "This notebook runs the complete analysis for the paper \"The Human-AI Collaboration Frontier and the Quality of Science\".\n",
    "\n",
    "**Instructions:**\n",
    "1. Click \"Open in Colab\" badge or open this notebook in Google Colab\n",
    "2. Set your data folder path (can be Google Drive) in Section 1\n",
    "3. Optionally set GitHub token to push results\n",
    "4. Run all cells (Runtime ‚Üí Run all)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/leippold/HAI-Frontier/blob/main/master_analysis.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VlX5Jnijm8hJ"
   },
   "source": [
    "## 1. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import userdata\n",
    "\n",
    "# Get token from Colab Secrets (set once in sidebar, persists across sessions)\n",
    "try:\n",
    "    GITHUB_TOKEN = userdata.get('GITHUB_TOKEN')\n",
    "    print(\"GitHub token loaded from Colab Secrets\")\n",
    "except:\n",
    "    GITHUB_TOKEN = None\n",
    "    print(\"No GitHub token found - will skip git push operations\")"
   ],
   "metadata": {
    "id": "G9CS0957nZ-k",
    "outputId": "51ba0c70-ed77-4515-c3f3-0e33245395d2",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "GitHub token loaded from Colab Secrets\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Kid1Hv9tm8hK"
   },
   "outputs": [],
   "source": [
    "#@title Data & GitHub Configuration { display-mode: \"form\" }\n",
    "\n",
    "#@markdown ### Data Location\n",
    "#@markdown Set the path to your data folder (supports Google Drive):\n",
    "DATA_PATH = \"/content/drive/MyDrive/HAI_Data\"  #@param {type:\"string\"}\n",
    "\n",
    "\n",
    "#@markdown Expected files in DATA_PATH:\n",
    "#@markdown - `retraction_watch.csv`\n",
    "#@markdown - `all_problematic_papers.csv`\n",
    "#@markdown - `iclr_pangram_submissions.csv` (optional)\n",
    "#@markdown - `iclr_pangram_reviews.csv` (optional)\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown ### GitHub Configuration (optional, for pushing results)\n",
    "# GITHUB_TOKEN = \"\"  #@param {type:\"string\"}\n",
    "GITHUB_USER = \"leippold\"  #@param {type:\"string\"}\n",
    "REPO_NAME = \"HAI-Frontier\"  #@param {type:\"string\"}\n",
    "\n",
    "# # Validate\n",
    "# print(f\"üìÇ Data folder: {DATA_PATH}\")\n",
    "# if not GITHUB_TOKEN:\n",
    "#     print(\"‚ö†Ô∏è  No GitHub token set. You can still run analyses but cannot push changes.\")\n",
    "# else:\n",
    "#     print(\"‚úì GitHub token configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S1bEYo8rm8hL"
   },
   "source": [
    "## 2. Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Gbw_V43mm8hM",
    "outputId": "b4f7b9fd-c136-4f1d-e690-db613c7b0297",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n",
      "‚úì Google Drive mounted\n"
     ]
    }
   ],
   "source": [
    "#@title Mount Google Drive (if using Drive for data)\n",
    "\n",
    "# Only run this if your DATA_PATH is in Google Drive\n",
    "if DATA_PATH.startswith(\"/content/drive\"):\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    print(\"‚úì Google Drive mounted\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è  Skipping Drive mount (DATA_PATH is not in Drive)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "nTK_e3Ucm8hM",
    "outputId": "83b2e945-462b-4ee4-aeed-a2d2727ec160",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m349.3/349.3 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m117.3/117.3 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Building wheel for autograd-gamma (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "‚úì Dependencies installed\n"
     ]
    }
   ],
   "source": [
    "#@title Install Dependencies\n",
    "!pip install lifelines scipy statsmodels seaborn --quiet\n",
    "print(\"‚úì Dependencies installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "W4Vn8J-sm8hM",
    "outputId": "fb4d5d73-2520-4b24-81e0-c0f7cc037f2b",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/content\n",
      "Cloning into 'HAI-Frontier'...\n",
      "remote: Enumerating objects: 200, done.\u001b[K\n",
      "remote: Counting objects: 100% (41/41), done.\u001b[K\n",
      "remote: Compressing objects: 100% (22/22), done.\u001b[K\n",
      "remote: Total 200 (delta 25), reused 24 (delta 19), pack-reused 159 (from 1)\u001b[K\n",
      "Receiving objects: 100% (200/200), 205.53 KiB | 2.78 MiB/s, done.\n",
      "Resolving deltas: 100% (99/99), done.\n",
      "/content/HAI-Frontier\n",
      "\n",
      "üìÅ Repository structure:\n",
      "./README.md\n",
      "./inline_display.py\n",
      "./iclr_analysis/generate_tables.py\n",
      "./iclr_analysis/analysis/collaboration_hypothesis.py\n",
      "./iclr_analysis/analysis/run_all.py\n",
      "./iclr_analysis/analysis/effort_proxies.py\n",
      "./iclr_analysis/analysis/within_paper.py\n",
      "./iclr_analysis/analysis/heterogeneity.py\n",
      "./iclr_analysis/analysis/echo_chamber.py\n",
      "./iclr_analysis/analysis/confidence.py\n",
      "./iclr_analysis/analysis/__init__.py\n",
      "./iclr_analysis/README.md\n",
      "./iclr_analysis/src/stats_utils.py\n",
      "./iclr_analysis/src/data_loading.py\n",
      "./iclr_analysis/src/__init__.py\n",
      "./iclr_analysis/src/plotting_enhanced.py\n",
      "./iclr_analysis/src/plotting.py\n",
      "./iclr_analysis/src/constants.py\n",
      "./retraction_analysis/run_all.py\n",
      "./retraction_analysis/README.md\n"
     ]
    }
   ],
   "source": [
    "#@title Clone Repository from GitHub\n",
    "import os\n",
    "\n",
    "# Ensure we're in a valid directory\n",
    "%cd /content\n",
    "\n",
    "# Clean up any existing clone\n",
    "!rm -rf /content/{REPO_NAME}\n",
    "\n",
    "# Clone the repo\n",
    "if GITHUB_TOKEN:\n",
    "    !git clone https://{GITHUB_TOKEN}@github.com/{GITHUB_USER}/{REPO_NAME}.git\n",
    "else:\n",
    "    !git clone https://github.com/{GITHUB_USER}/{REPO_NAME}.git\n",
    "\n",
    "# Change to repo directory\n",
    "%cd /content/{REPO_NAME}\n",
    "\n",
    "# Show structure\n",
    "print(\"\\nüìÅ Repository structure:\")\n",
    "!find . -type f \\( -name \"*.py\" -o -name \"*.md\" \\) | head -20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hRJhEY2gm8hN",
    "outputId": "5cf083cd-1e19-44af-bd8d-0f43aab453d9",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [],
   "source": "#@title Setup Python Path and Imports\nimport sys\nimport os\nimport importlib.util\n\n# Repository path\nREPO_PATH = f\"/content/{REPO_NAME}\"\n\n# Output directory - use last_results/master_analysis for organized results\nOUTPUT_DIR = f\"{REPO_PATH}/last_results/master_analysis\"\n\n# Create output directories\nos.makedirs(f\"{OUTPUT_DIR}/figures\", exist_ok=True)\nos.makedirs(f\"{OUTPUT_DIR}/tables\", exist_ok=True)\n\n# Helper function to load modules by explicit path (avoids name conflicts)\ndef load_module_from_path(module_name, file_path):\n    \"\"\"Load a Python module from an explicit file path.\"\"\"\n    spec = importlib.util.spec_from_file_location(module_name, file_path)\n    module = importlib.util.module_from_spec(spec)\n    sys.modules[module_name] = module\n    spec.loader.exec_module(module)\n    return module\n\n# Add paths for dependencies (but NOT for run_all - we'll load those explicitly)\nsys.path.insert(0, f\"{REPO_PATH}/retraction_analysis\")\nsys.path.insert(0, f\"{REPO_PATH}/iclr_analysis\")\n\n# Common imports\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom IPython.display import display, HTML, Markdown, Image\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Configure matplotlib for inline display\n%matplotlib inline\nplt.rcParams['figure.figsize'] = [10, 6]\nplt.rcParams['figure.dpi'] = 100\n\nprint(\"‚úì Environment configured\")\nprint(f\"  Repository: {REPO_PATH}\")\nprint(f\"  Data folder: {DATA_PATH}\")\nprint(f\"  Output folder: {OUTPUT_DIR}\")"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "fO8LQxh_m8hN",
    "outputId": "4ea886c1-567f-4434-9f39-2cbad7c282b3",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "üìä Checking data files in: /content/drive/MyDrive/HAI_Data\n",
      "\n",
      "  ‚úì retraction_watch.csv (59.3 MB)\n",
      "  ‚úì all_problematic_papers.csv (244.7 MB)\n",
      "  ‚úì iclr_pangram_submissions.csv (7.6 MB)\n",
      "  ‚úì iclr_pangram_reviews.csv (228.0 MB)\n",
      "\n",
      "‚úì All required files found!\n"
     ]
    }
   ],
   "source": [
    "#@title Verify Data Files\n",
    "import os\n",
    "\n",
    "print(f\"üìä Checking data files in: {DATA_PATH}\\n\")\n",
    "\n",
    "required_files = [\n",
    "    (\"retraction_watch.csv\", \"Retraction Watch data\", True),\n",
    "    (\"all_problematic_papers.csv\", \"Problematic Papers data\", True),\n",
    "    (\"iclr_pangram_submissions.csv\", \"ICLR Submissions\", False),\n",
    "    (\"iclr_pangram_reviews.csv\", \"ICLR Reviews\", False),\n",
    "]\n",
    "\n",
    "all_required_found = True\n",
    "for filename, description, required in required_files:\n",
    "    filepath = os.path.join(DATA_PATH, filename)\n",
    "    if os.path.exists(filepath):\n",
    "        size = os.path.getsize(filepath) / 1024 / 1024  # MB\n",
    "        print(f\"  ‚úì {filename} ({size:.1f} MB)\")\n",
    "    else:\n",
    "        if required:\n",
    "            print(f\"  ‚ùå {filename} - REQUIRED but not found!\")\n",
    "            all_required_found = False\n",
    "        else:\n",
    "            print(f\"  ‚ö†Ô∏è {filename} - optional, not found\")\n",
    "\n",
    "if all_required_found:\n",
    "    print(\"\\n‚úì All required files found!\")\n",
    "else:\n",
    "    print(\"\\n‚ùå Some required files missing. Please check DATA_PATH.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fNOaibrNm8hO"
   },
   "source": [
    "## 3. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sks0I2Zim8hO",
    "outputId": "497a4b6a-f6d4-4837-bbb3-6c623f6cff99",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 387
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "‚úì Retraction data loaded: 67,989 records\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "   Record ID                                              Title  \\\n",
       "0      68582  Study of the ground state properties of 8Li an...   \n",
       "1      68581  Study of some biochemical indicators levels in...   \n",
       "2      68580  Study of histological structure of albino rat ...   \n",
       "\n",
       "                                             Subject  \\\n",
       "0                                     (PHY) Physics;   \n",
       "1  (BLS) Parasitology;(HSC) Medicine - Infectious...   \n",
       "2  (HSC) Medicine - Pharmacology;(HSC) Medicine -...   \n",
       "\n",
       "                                         Institution  \\\n",
       "0  Department of Physics, College of Science, Uni...   \n",
       "1  Faculty of Applied Science, Samarra University...   \n",
       "2  College Medical and health technologies Univer...   \n",
       "\n",
       "                      Journal       Publisher Country  \\\n",
       "0  AIP Conference Proceedings  AIP Publishing    Iraq   \n",
       "1  AIP Conference Proceedings  AIP Publishing    Iraq   \n",
       "2  AIP Conference Proceedings  AIP Publishing    Iraq   \n",
       "\n",
       "                                              Author URLS  \\\n",
       "0                    Hawraa K Mahdi;Ahmed N Abdullah  NaN   \n",
       "1  Wasan Abdulmunem Taha;Ohood Mozahim Shakir;Mar...  NaN   \n",
       "2  Noor M Hasnawi;Jabbar Abadi Alaridhi;Douaa M M...  NaN   \n",
       "\n",
       "                  ArticleType   RetractionDate      RetractionDOI  \\\n",
       "0  Conference Abstract/Paper;  10/24/2025 0:00  10.1063/5.0181894   \n",
       "1  Conference Abstract/Paper;  10/24/2025 0:00  10.1063/5.0182763   \n",
       "2  Conference Abstract/Paper;  10/24/2025 0:00  10.1063/5.0182531   \n",
       "\n",
       "   RetractionPubMedID OriginalPaperDate   OriginalPaperDOI  \\\n",
       "0                 0.0   12/22/2023 0:00  10.1063/5.0181894   \n",
       "1                 0.0   12/22/2023 0:00  10.1063/5.0182763   \n",
       "2                 0.0   12/22/2023 0:00  10.1063/5.0182531   \n",
       "\n",
       "   OriginalPaperPubMedID RetractionNature  \\\n",
       "0                    0.0       Retraction   \n",
       "1                    0.0       Retraction   \n",
       "2                    0.0       Retraction   \n",
       "\n",
       "                                              Reason Paywalled  \\\n",
       "0  Concerns/Issues about Peer Review;Concerns/Iss...        No   \n",
       "1  Concerns/Issues about Peer Review;Concerns/Iss...        No   \n",
       "2  Concerns/Issues about Peer Review;Concerns/Iss...        No   \n",
       "\n",
       "                                               Notes  \n",
       "0  Original articles updated to include retractio...  \n",
       "1  Original articles updated to include retractio...  \n",
       "2  Original articles updated to include retractio...  "
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-d667b065-d62a-4a3a-bc2b-ab47476b3eed\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Record ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Institution</th>\n",
       "      <th>Journal</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Country</th>\n",
       "      <th>Author</th>\n",
       "      <th>URLS</th>\n",
       "      <th>ArticleType</th>\n",
       "      <th>RetractionDate</th>\n",
       "      <th>RetractionDOI</th>\n",
       "      <th>RetractionPubMedID</th>\n",
       "      <th>OriginalPaperDate</th>\n",
       "      <th>OriginalPaperDOI</th>\n",
       "      <th>OriginalPaperPubMedID</th>\n",
       "      <th>RetractionNature</th>\n",
       "      <th>Reason</th>\n",
       "      <th>Paywalled</th>\n",
       "      <th>Notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68582</td>\n",
       "      <td>Study of the ground state properties of 8Li an...</td>\n",
       "      <td>(PHY) Physics;</td>\n",
       "      <td>Department of Physics, College of Science, Uni...</td>\n",
       "      <td>AIP Conference Proceedings</td>\n",
       "      <td>AIP Publishing</td>\n",
       "      <td>Iraq</td>\n",
       "      <td>Hawraa K Mahdi;Ahmed N Abdullah</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Conference Abstract/Paper;</td>\n",
       "      <td>10/24/2025 0:00</td>\n",
       "      <td>10.1063/5.0181894</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12/22/2023 0:00</td>\n",
       "      <td>10.1063/5.0181894</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Retraction</td>\n",
       "      <td>Concerns/Issues about Peer Review;Concerns/Iss...</td>\n",
       "      <td>No</td>\n",
       "      <td>Original articles updated to include retractio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68581</td>\n",
       "      <td>Study of some biochemical indicators levels in...</td>\n",
       "      <td>(BLS) Parasitology;(HSC) Medicine - Infectious...</td>\n",
       "      <td>Faculty of Applied Science, Samarra University...</td>\n",
       "      <td>AIP Conference Proceedings</td>\n",
       "      <td>AIP Publishing</td>\n",
       "      <td>Iraq</td>\n",
       "      <td>Wasan Abdulmunem Taha;Ohood Mozahim Shakir;Mar...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Conference Abstract/Paper;</td>\n",
       "      <td>10/24/2025 0:00</td>\n",
       "      <td>10.1063/5.0182763</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12/22/2023 0:00</td>\n",
       "      <td>10.1063/5.0182763</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Retraction</td>\n",
       "      <td>Concerns/Issues about Peer Review;Concerns/Iss...</td>\n",
       "      <td>No</td>\n",
       "      <td>Original articles updated to include retractio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68580</td>\n",
       "      <td>Study of histological structure of albino rat ...</td>\n",
       "      <td>(HSC) Medicine - Pharmacology;(HSC) Medicine -...</td>\n",
       "      <td>College Medical and health technologies Univer...</td>\n",
       "      <td>AIP Conference Proceedings</td>\n",
       "      <td>AIP Publishing</td>\n",
       "      <td>Iraq</td>\n",
       "      <td>Noor M Hasnawi;Jabbar Abadi Alaridhi;Douaa M M...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Conference Abstract/Paper;</td>\n",
       "      <td>10/24/2025 0:00</td>\n",
       "      <td>10.1063/5.0182531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12/22/2023 0:00</td>\n",
       "      <td>10.1063/5.0182531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Retraction</td>\n",
       "      <td>Concerns/Issues about Peer Review;Concerns/Iss...</td>\n",
       "      <td>No</td>\n",
       "      <td>Original articles updated to include retractio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d667b065-d62a-4a3a-bc2b-ab47476b3eed')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-d667b065-d62a-4a3a-bc2b-ab47476b3eed button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-d667b065-d62a-4a3a-bc2b-ab47476b3eed');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-9fbaefd2-031c-4026-b841-acd68c3db70a\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9fbaefd2-031c-4026-b841-acd68c3db70a')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-9fbaefd2-031c-4026-b841-acd68c3db70a button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "repr_error": "Out of range float values are not JSON compliant: nan"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "#@title Load Datasets\n",
    "\n",
    "# Helper function to clean ai_percentage column\n",
    "def clean_ai_percentage(df, col='ai_percentage'):\n",
    "    \"\"\"Convert ai_percentage from string ('100%') to numeric (100.0).\"\"\"\n",
    "    if col in df.columns and df[col].dtype == 'object':\n",
    "        df[col] = df[col].astype(str).str.replace('%', '', regex=False)\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    return df\n",
    "\n",
    "# Load retraction data\n",
    "try:\n",
    "    retraction_df = pd.read_csv(f\"{DATA_PATH}/retraction_watch.csv\")\n",
    "    print(f\"‚úì Retraction data loaded: {len(retraction_df):,} records\")\n",
    "    display(retraction_df.head(3))\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"‚ö†Ô∏è  Retraction data not found: {e}\")\n",
    "    retraction_df = None\n",
    "\n",
    "# Load problematic papers data\n",
    "try:\n",
    "    problematic_df = pd.read_csv(f\"{DATA_PATH}/all_problematic_papers.csv\")\n",
    "    print(f\"\\n‚úì Problematic papers data loaded: {len(problematic_df):,} records\")\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ö†Ô∏è  Problematic papers data not found\")\n",
    "    problematic_df = None\n",
    "\n",
    "# Load ICLR data if available\n",
    "try:\n",
    "    iclr_submissions = pd.read_csv(f\"{DATA_PATH}/iclr_pangram_submissions.csv\")\n",
    "    iclr_reviews = pd.read_csv(f\"{DATA_PATH}/iclr_pangram_reviews.csv\")\n",
    "\n",
    "    # Clean ai_percentage column (handles '100%' -> 100.0)\n",
    "    iclr_submissions = clean_ai_percentage(iclr_submissions)\n",
    "    iclr_reviews = clean_ai_percentage(iclr_reviews)\n",
    "\n",
    "    # Clean other numeric columns\n",
    "    numeric_cols = ['avg_rating', 'soundness', 'presentation', 'contribution', 'rating', 'confidence']\n",
    "    for col in numeric_cols:\n",
    "        if col in iclr_submissions.columns:\n",
    "            iclr_submissions[col] = pd.to_numeric(iclr_submissions[col], errors='coerce')\n",
    "        if col in iclr_reviews.columns:\n",
    "            iclr_reviews[col] = pd.to_numeric(iclr_reviews[col], errors='coerce')\n",
    "\n",
    "    print(f\"\\n‚úì ICLR submissions loaded: {len(iclr_submissions):,} records\")\n",
    "    print(f\"‚úì ICLR reviews loaded: {len(iclr_reviews):,} records\")\n",
    "    print(f\"  ai_percentage dtype: {iclr_submissions['ai_percentage'].dtype}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"\\n‚ö†Ô∏è  ICLR data not found (optional)\")\n",
    "    iclr_submissions = None\n",
    "    iclr_reviews = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TvJhPuy3m8hO"
   },
   "source": [
    "---\n",
    "# Part A: Retraction Analysis\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yz0eJo8pm8hO"
   },
   "outputs": [],
   "source": [
    "#@title Run Retraction Analysis\n",
    "\n",
    "# Load retraction_analysis/run_all.py explicitly by path (avoids conflict with iclr_analysis/analysis/run_all.py)\n",
    "retraction_runner = load_module_from_path(\n",
    "    \"retraction_run_all\",\n",
    "    f\"{REPO_PATH}/retraction_analysis/run_all.py\"\n",
    ")\n",
    "\n",
    "# Run all retraction analyses\n",
    "if retraction_df is not None:\n",
    "    retraction_results = retraction_runner.run_all_analyses(\n",
    "        retraction_path=f\"{DATA_PATH}/retraction_watch.csv\",\n",
    "        problematic_path=f\"{DATA_PATH}/all_problematic_papers.csv\",\n",
    "        output_dir=OUTPUT_DIR\n",
    "    )\n",
    "    print(\"\\n‚úì Retraction analysis complete!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Skipping retraction analysis - data not loaded\")\n",
    "    retraction_results = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7k3637-hm8hP"
   },
   "outputs": [],
   "source": [
    "#@title Display Generated Figures (Retraction Analysis)\n",
    "import glob\n",
    "from IPython.display import Image, display\n",
    "\n",
    "print(\"üìà Generated Figures:\\n\")\n",
    "\n",
    "# Find all generated figures\n",
    "figure_files = sorted(glob.glob(f\"{OUTPUT_DIR}/figures/*.png\"))\n",
    "\n",
    "if figure_files:\n",
    "    for fig_path in figure_files:\n",
    "        fig_name = os.path.basename(fig_path)\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"üìä {fig_name}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        display(Image(filename=fig_path, width=800))\n",
    "else:\n",
    "    print(\"No figures generated yet. Run the analysis cells above first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wysyNUl3m8hP"
   },
   "outputs": [],
   "source": [
    "#@title Display Generated LaTeX Tables\n",
    "\n",
    "print(\"üìã Generated Tables:\\n\")\n",
    "\n",
    "# Find all generated tables\n",
    "table_files = sorted(glob.glob(f\"{OUTPUT_DIR}/tables/*.tex\"))\n",
    "\n",
    "if table_files:\n",
    "    for table_path in table_files:\n",
    "        table_name = os.path.basename(table_path)\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"üìÑ {table_name}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        with open(table_path, 'r') as f:\n",
    "            content = f.read()\n",
    "            print(content[:2000])\n",
    "            if len(content) > 2000:\n",
    "                print(\"... [truncated]\")\n",
    "else:\n",
    "    print(\"No tables generated yet. Run the analysis cells above first.\")"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#@title Generate Enhanced Retraction Figures (Publication Quality)\n",
    "#@markdown Creates professional, publication-quality figures for the retraction analysis.\n",
    "#@markdown Matches the style of the ICLR figures with KDE, gradient fills, and statistics boxes.\n",
    "\n",
    "if retraction_results is not None:\n",
    "    print(\"=\"*70)\n",
    "    print(\"GENERATING ENHANCED RETRACTION FIGURES\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    # Load enhanced plotting module for retraction analysis\n",
    "    from retraction_analysis_modules.plotting_enhanced import generate_all_retraction_figures\n",
    "\n",
    "    figures_dir = f\"{OUTPUT_DIR}/figures\"\n",
    "\n",
    "    # Get the processed dataframe from retraction_results\n",
    "    if 'data' in retraction_results:\n",
    "        df_for_figures = retraction_results['data']\n",
    "    else:\n",
    "        # Reload and process if not available\n",
    "        from retraction_src.data_loading import load_data, define_ai_cohorts\n",
    "        rw_df, prob_df = load_data(\n",
    "            f\"{DATA_PATH}/retraction_watch.csv\",\n",
    "            f\"{DATA_PATH}/all_problematic_papers.csv\",\n",
    "            start_year=2005\n",
    "        )\n",
    "        df_for_figures = define_ai_cohorts(rw_df, prob_df)\n",
    "\n",
    "    print(f\"\\nData for figures: {len(df_for_figures):,} records\")\n",
    "\n",
    "    # Generate ALL enhanced figures\n",
    "    print(\"\\nGenerating enhanced figures...\")\n",
    "    enhanced_figures = generate_all_retraction_figures(\n",
    "        df=df_for_figures,\n",
    "        output_dir=figures_dir,\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "    # Display all generated enhanced figures\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"DISPLAYING ENHANCED RETRACTION FIGURES\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    for name, path in enhanced_figures.items():\n",
    "        print(f\"\\n{'‚îÄ'*60}\")\n",
    "        print(f\"üìä {name}: {os.path.basename(path)}\")\n",
    "        print(f\"{'‚îÄ'*60}\")\n",
    "        display(Image(filename=path, width=800))\n",
    "\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"‚úì Generated {len(enhanced_figures)} enhanced retraction figures!\")\n",
    "    print(f\"  Location: {figures_dir}/\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Skipping enhanced figures - retraction analysis not run\")"
   ],
   "metadata": {
    "id": "5lJXqQg1m8hP"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## Sample Construction Audit\n",
    "\n",
    "This section provides a complete audit trail of sample construction to address any concerns about cohort definition inconsistencies.\n",
    "---"
   ],
   "metadata": {
    "id": "6K4-BYEtm8hP"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#@title Run Sample Construction Audit\n",
    "#@markdown This generates a complete audit trail of sample construction with step-by-step exclusion counts.\n",
    "\n",
    "from retraction_analysis_modules.sample_construction import SampleConstructionAudit\n",
    "\n",
    "if retraction_df is not None:\n",
    "    print(\"=\"*70)\n",
    "    print(\"SAMPLE CONSTRUCTION AUDIT\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    # Initialize audit\n",
    "    audit = SampleConstructionAudit(\n",
    "        retraction_path=f\"{DATA_PATH}/retraction_watch.csv\",\n",
    "        problematic_path=f\"{DATA_PATH}/all_problematic_papers.csv\"\n",
    "    )\n",
    "\n",
    "    # Run the complete audit\n",
    "    final_df = audit.load_and_process()\n",
    "\n",
    "    # Display sample flow table\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"SAMPLE FLOW TABLE\")\n",
    "    print(\"=\"*70)\n",
    "    flow_df = audit.get_flow_table()\n",
    "    display(flow_df)\n",
    "\n",
    "    # Display final cohort breakdown\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"FINAL COHORT BREAKDOWN\")\n",
    "    print(\"=\"*70)\n",
    "    if final_df is not None and len(final_df) > 0:\n",
    "        if 'is_ai' in final_df.columns:\n",
    "            ai_papers = final_df['is_ai'].sum()\n",
    "            human_papers = len(final_df) - ai_papers\n",
    "            print(f\"  Total analytic sample: N = {len(final_df):,}\")\n",
    "            print(f\"  AI-assisted papers:    n = {ai_papers:,} ({100*ai_papers/len(final_df):.1f}%)\")\n",
    "            print(f\"  Human-only papers:     n = {human_papers:,} ({100*human_papers/len(final_df):.1f}%)\")\n",
    "\n",
    "    # Generate outputs\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"GENERATING AUDIT OUTPUTS\")\n",
    "    print(\"=\"*70)\n",
    "    audit.generate_full_report(output_dir=OUTPUT_DIR)\n",
    "\n",
    "    # Display LaTeX table for paper\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"LATEX SAMPLE FLOW TABLE (for paper appendix)\")\n",
    "    print(\"=\"*70)\n",
    "    latex_table = audit.to_latex_flow_table()\n",
    "    print(latex_table)\n",
    "\n",
    "    # Verify consistency with expected values\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"CONSISTENCY CHECK\")\n",
    "    print(\"=\"*70)\n",
    "    # Check against the values mentioned in the paper\n",
    "    verification = audit.verify_consistency(\n",
    "        expected_total=58454,\n",
    "        expected_ai=18159,\n",
    "        expected_human=40295\n",
    "    )\n",
    "\n",
    "    print(f\"  Actual total:  {verification['actual_total']:,}\")\n",
    "    print(f\"  Actual AI:     {verification['actual_ai']:,}\")\n",
    "    print(f\"  Actual Human:  {verification['actual_human']:,}\")\n",
    "    print()\n",
    "\n",
    "    if verification['checks_passed']:\n",
    "        print(\"  ‚úì All consistency checks PASSED\")\n",
    "    else:\n",
    "        print(\"  ‚úó Consistency checks found discrepancies:\")\n",
    "        for disc in verification['discrepancies']:\n",
    "            print(f\"    - {disc}\")\n",
    "        print()\n",
    "        print(\"  NOTE: Discrepancies may be due to:\")\n",
    "        print(\"    - Database updates since paper submission\")\n",
    "        print(\"    - Different extraction dates\")\n",
    "        print(\"    - Variations in filtering criteria\")\n",
    "\n",
    "    print(\"\\n‚úì Sample construction audit complete!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Skipping sample audit - retraction data not loaded\")"
   ],
   "metadata": {
    "id": "4dp_dJvzm8hQ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZIyUISYLm8hQ"
   },
   "source": [
    "---\n",
    "# Part B: ICLR Analysis\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W-xLl2Jlm8hQ"
   },
   "outputs": [],
   "source": [
    "#@title Run ICLR Analysis\n",
    "\n",
    "if iclr_submissions is not None and iclr_reviews is not None:\n",
    "    # Load iclr_analysis/analysis/run_all.py explicitly by path\n",
    "    iclr_runner = load_module_from_path(\n",
    "        \"iclr_run_all\",\n",
    "        f\"{REPO_PATH}/iclr_analysis/analysis/run_all.py\"\n",
    "    )\n",
    "\n",
    "    iclr_results = iclr_runner.run_all(\n",
    "        submissions_path=f\"{DATA_PATH}/iclr_pangram_submissions.csv\",\n",
    "        reviews_path=f\"{DATA_PATH}/iclr_pangram_reviews.csv\",\n",
    "        output_dir=OUTPUT_DIR\n",
    "    )\n",
    "    print(\"\\n‚úì ICLR analysis complete!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Skipping ICLR analysis - data not loaded\")\n",
    "    iclr_results = None"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## Enhanced Visualizations (Publication Quality)\n",
    "\n",
    "Generate professional, single-panel figures for the collaboration analysis.\n",
    "---"
   ],
   "metadata": {
    "id": "N0EjqDd5m8hQ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#@title Generate ALL Publication-Quality Figures (Single Panels)\n",
    "#@markdown Creates individual, professional figures for ALL analysis panels.\n",
    "#@markdown Includes KDE-based within-paper analysis and handles integer clustering.\n",
    "\n",
    "if iclr_submissions is not None and iclr_reviews is not None:\n",
    "    print(\"=\"*70)\n",
    "    print(\"GENERATING ALL PUBLICATION-QUALITY FIGURES\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    # Load enhanced plotting module\n",
    "    from src.plotting_enhanced import generate_all_iclr_figures\n",
    "    from analysis.within_paper import prepare_within_paper_data\n",
    "\n",
    "    figures_dir = f\"{OUTPUT_DIR}/figures\"\n",
    "\n",
    "    # Prepare within-paper data if possible\n",
    "    try:\n",
    "        paper_ratings = prepare_within_paper_data(iclr_reviews, iclr_submissions)\n",
    "        print(f\"\\nWithin-paper data: {len(paper_ratings)} papers with both reviewer types\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nWithin-paper data not available: {e}\")\n",
    "        paper_ratings = None\n",
    "\n",
    "    # Generate ALL figures as individual files\n",
    "    print(\"\\nGenerating individual figures...\")\n",
    "    figures = generate_all_iclr_figures(\n",
    "        submissions_df=iclr_submissions,\n",
    "        reviews_df=iclr_reviews,\n",
    "        output_dir=figures_dir,\n",
    "        paper_ratings=paper_ratings,\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "    # Display all generated figures\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"DISPLAYING GENERATED FIGURES\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    for name, path in figures.items():\n",
    "        print(f\"\\n{'‚îÄ'*60}\")\n",
    "        print(f\"üìä {name}: {os.path.basename(path)}\")\n",
    "        print(f\"{'‚îÄ'*60}\")\n",
    "        display(Image(filename=path, width=800))\n",
    "\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"‚úì Generated {len(figures)} publication-quality figures!\")\n",
    "    print(f\"  Location: {figures_dir}/\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Skipping enhanced figures - ICLR data not loaded\")"
   ],
   "metadata": {
    "id": "8RpUiupIm8hQ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nQwPl6Jrm8hR"
   },
   "source": [
    "---\n",
    "# Part C: Summary Statistics\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HP7oVUTxm8hR"
   },
   "outputs": [],
   "source": [
    "#@title Generate Summary Statistics\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ANALYSIS SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if retraction_df is not None:\n",
    "    print(f\"\\nüìä Retraction Dataset:\")\n",
    "    print(f\"   Total papers: {len(retraction_df):,}\")\n",
    "    if 'is_ai' in retraction_df.columns:\n",
    "        ai_count = retraction_df['is_ai'].sum()\n",
    "        print(f\"   AI-flagged papers: {ai_count:,} ({100*ai_count/len(retraction_df):.1f}%)\")\n",
    "    if 'pub_year' in retraction_df.columns:\n",
    "        print(f\"   Year range: {retraction_df['pub_year'].min()} - {retraction_df['pub_year'].max()}\")\n",
    "\n",
    "if iclr_submissions is not None:\n",
    "    print(f\"\\nüìä ICLR Dataset:\")\n",
    "    print(f\"   Total submissions: {len(iclr_submissions):,}\")\n",
    "    print(f\"   Total reviews: {len(iclr_reviews):,}\")\n",
    "\n",
    "# Count outputs\n",
    "import glob\n",
    "n_figures = len(glob.glob(f\"{OUTPUT_DIR}/figures/*.png\"))\n",
    "n_tables = len(glob.glob(f\"{OUTPUT_DIR}/tables/*.tex\"))\n",
    "print(f\"\\nüìÅ Generated Outputs:\")\n",
    "print(f\"   {n_figures} figures\")\n",
    "print(f\"   {n_tables} tables\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-HLjwYjVm8hR"
   },
   "source": [
    "---\n",
    "# Part D: Push Results to GitHub\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DAZ2dyMtm8hR"
   },
   "outputs": [],
   "source": "#@title Push RESULTS to GitHub (Tables & Figures Only)\n#@markdown Automatically pushes only the analysis outputs to GitHub.\n#@markdown This ensures your paper always references the latest empirical results.\n\ndef push_results_to_github(\n    repo_path=\"/content/HAI-Frontier\",\n    branch=\"main\",\n    commit_message=None,\n    github_token=None\n):\n    \"\"\"\n    Push only RESULTS (figures, tables) to GitHub - not notebooks or code.\n    \n    This solves the 'fat finger problem' by ensuring reproducibility:\n    - Run notebook ‚Üí Results auto-pushed ‚Üí Paper references match outputs\n    \n    Results are organized in: last_results/master_analysis/\n    \"\"\"\n    import os\n    import subprocess\n    from datetime import datetime\n    \n    # Get token\n    token = github_token\n    if not token:\n        try:\n            from google.colab import userdata\n            token = userdata.get('GITHUB_TOKEN')\n        except:\n            pass\n    \n    if not token:\n        print(\"‚ùå No GitHub token! Add GITHUB_TOKEN to Colab secrets.\")\n        return False\n    \n    os.chdir(repo_path)\n    \n    # Configure git\n    subprocess.run(['git', 'config', 'user.email', 'colab@notebook.local'], capture_output=True)\n    subprocess.run(['git', 'config', 'user.name', 'Colab Analysis Runner'], capture_output=True)\n    \n    # Define ONLY result files to push (organized in last_results/master_analysis/)\n    result_patterns = [\n        'last_results/master_analysis/figures/*.png',\n        'last_results/master_analysis/figures/*.pdf', \n        'last_results/master_analysis/tables/*.tex',\n        'last_results/master_analysis/tables/*.csv',\n        'last_results/master_analysis/*.csv',\n        'last_results/master_analysis/*.tex',\n    ]\n    \n    # Add result files\n    print(\"üìä Adding result files from last_results/master_analysis/...\")\n    files_added = []\n    for pattern in result_patterns:\n        result = subprocess.run(f'git add {pattern} 2>/dev/null', shell=True, capture_output=True)\n        # Check what was actually added\n        import glob\n        matched = glob.glob(os.path.join(repo_path, pattern))\n        files_added.extend(matched)\n    \n    if not files_added:\n        print(\"‚ÑπÔ∏è  No result files to push.\")\n        return True\n    \n    print(f\"   Found {len(files_added)} result files\")\n    \n    # Check if there are changes\n    status = subprocess.run(['git', 'status', '--porcelain'], capture_output=True, text=True)\n    if not status.stdout.strip():\n        print(\"‚ÑπÔ∏è  No changes to commit (results unchanged)\")\n        return True\n    \n    # Show what's being committed\n    print(\"\\nüìù Files to commit:\")\n    for line in status.stdout.strip().split('\\n')[:15]:\n        print(f\"   {line}\")\n    if len(status.stdout.strip().split('\\n')) > 15:\n        print(f\"   ... and {len(status.stdout.strip().split(chr(10))) - 15} more\")\n    \n    # Create commit message\n    if not commit_message:\n        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n        commit_message = f\"Update analysis results from master_analysis.ipynb ({timestamp})\"\n    \n    # Commit\n    result = subprocess.run(\n        ['git', 'commit', '-m', commit_message],\n        capture_output=True, text=True\n    )\n    if result.returncode != 0:\n        print(f\"‚ùå Commit failed: {result.stderr}\")\n        return False\n    \n    print(f\"\\n‚úì Committed: {commit_message}\")\n    \n    # Push\n    print(\"\\nüì§ Pushing to GitHub...\")\n    result = subprocess.run(\n        ['git', 'push', 'origin', branch],\n        capture_output=True, text=True\n    )\n    if result.returncode != 0:\n        print(f\"‚ùå Push failed: {result.stderr}\")\n        return False\n    \n    print(f\"‚úì Successfully pushed to {branch}\")\n    print(f\"\\nüîó View at: https://github.com/{GITHUB_USER}/{REPO_NAME}/tree/{branch}/last_results/master_analysis\")\n    return True\n\n# ============================================================\n# AUTO-PUSH RESULTS\n# ============================================================\nprint(\"=\"*60)\nprint(\"PUSHING ANALYSIS RESULTS TO GITHUB\")\nprint(\"=\"*60)\n\nsuccess = push_results_to_github(\n    repo_path=f\"/content/{REPO_NAME}\",\n    branch=\"main\",\n    github_token=GITHUB_TOKEN\n)\n\nif success:\n    print(\"\\n\" + \"=\"*60)\n    print(\"‚úì Results synchronized with GitHub!\")\n    print(\"  Your paper now references the latest empirical outputs.\")\n    print(\"  Results location: last_results/master_analysis/\")\n    print(\"=\"*60)\nelse:\n    print(\"\\n‚ö†Ô∏è  Push failed - check token and permissions\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HpSz2UGdm8hR"
   },
   "source": [
    "---\n",
    "# Appendix: Download Outputs\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w7pfJjifm8hR"
   },
   "outputs": [],
   "source": [
    "#@title Download All Outputs as ZIP\n",
    "from google.colab import files\n",
    "import shutil\n",
    "\n",
    "# Create zip of outputs\n",
    "output_zip = \"/content/analysis_outputs.zip\"\n",
    "shutil.make_archive(\"/content/analysis_outputs\", 'zip', OUTPUT_DIR)\n",
    "\n",
    "print(f\"üì¶ Created: {output_zip}\")\n",
    "print(\"\\nClick below to download:\")\n",
    "files.download(output_zip)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  },
  "colab": {
   "provenance": [],
   "include_colab_link": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}